{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.11/site-packages (3.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.11/site-packages (3.12.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/anaconda3/lib/python3.11/site-packages (from h5py) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/lib/python3.11/site-packages (7.6.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from ipywidgets) (6.28.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/anaconda3/lib/python3.11/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=4.0.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/anaconda3/lib/python3.11/site-packages (from nbformat>=4.2.0->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/anaconda3/lib/python3.11/site-packages (from nbformat>=4.2.0->ipywidgets) (4.19.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (7.0.8)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /opt/anaconda3/lib/python3.11/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/anaconda3/lib/python3.11/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.3)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.10.0)\n",
      "Requirement already satisfied: overrides in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: websocket-client in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.58.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.6)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /opt/anaconda3/lib/python3.11/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.1.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2024.8.30)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.1)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.5)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mlxtend in /opt/anaconda3/lib/python3.11/site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install h5py\n",
    "%pip install ipywidgets\n",
    "%pip install mlxtend  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForMaskedLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from torch.utils.data import DataLoader\n",
    "# from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm # For processing bars\n",
    "import h5py\n",
    "import mlxtend\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug_smiles_fcs_freq_100.csv already exists. Skipping drug SMILES subsequence extraction.\n",
      "protein_fcs_freq_100.csv already exists. Skipping protein sequences subsequence extraction.\n",
      "drug_encoded.csv and protein_encoded.csv already exist. Skipping encoding step.\n",
      "   Drug id pdb_id\n",
      "0  DB05383   1NSI\n",
      "1  DB08814   1NSI\n",
      "2  DB08814   1MDI\n",
      "3  DB09092   1DJL\n",
      "4  DB09092   3ERY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating negative samples: 100%|██████████| 968/968 [00:00<00:00, 457011.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968\n",
      "968\n",
      "   Drug id pdb_id\n",
      "0  DB11800   4A69\n",
      "1  DB00607   2H8N\n",
      "2  DB01395   4BDW\n",
      "3  DB01236   1HVY\n",
      "4  DB00710   2LSQ\n",
      "Confirmed\n",
      "   Drug id pdb_id  label\n",
      "0  DB06211   3OC2      1\n",
      "1  DB05015   3C5K      1\n",
      "2  DB06603   4A69      1\n",
      "3  DB00598   2VAY      0\n",
      "4  DB09091   1RY7      0\n",
      "File merged_encodings.csv already exists. Skipping save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define file paths (adjust these as needed)\n",
    "DRUGBANK_CSV = \"drug_smiles.csv\"\n",
    "PROTEIN_CSV = \"pdb_sequences.csv\"\n",
    "INTERACTIONS_CSV = \"confirmed_interactions.csv\"  # should contain columns like \"Drug id\", \"pdb_id\"\n",
    "DRUG_ENCODED_CSV = \"drug_encoded.csv\"\n",
    "PROTEIN_ENCODED_CSV = \"protein_encoded.csv\"\n",
    "DRUG_FCS_CSV = \"drug_smiles_fcs_freq_100.csv\"\n",
    "PROTEIN_FCS_CSV = \"protein_fcs_freq_100.csv\"\n",
    "MERGED_ENCODING_CSV = \"merged_encodings.csv\"\n",
    "\n",
    "# --- (A) FCS Extraction and Ranking ---\n",
    "# (Assume the functions extract_fcs_subsequences_stream and filter_and_rank_fcs are defined as in your code)\n",
    "\n",
    "def extract_fcs_subsequences_stream(strings, min_length=2, max_length=None,\n",
    "                                      prune_every=1000, prune_threshold=5,\n",
    "                                      preserve_short_length=5):\n",
    "    subseq_counter = Counter()\n",
    "    for idx, s in enumerate(strings, 1):\n",
    "        n = len(s)\n",
    "        for i in range(n):\n",
    "            current_max = n - i if max_length is None else min(max_length, n - i)\n",
    "            for l in range(min_length, current_max + 1):\n",
    "                subseq = s[i:i+l]\n",
    "                subseq_counter[subseq] += 1\n",
    "        if idx % prune_every == 0:\n",
    "            subseq_counter = Counter({\n",
    "                k: v for k, v in subseq_counter.items()\n",
    "                if len(k) < preserve_short_length or v >= prune_threshold\n",
    "            })\n",
    "            print(f\"Processed {idx} sequences, counter pruned to {len(subseq_counter)} keys.\")\n",
    "    return subseq_counter\n",
    "\n",
    "def filter_and_rank_fcs(fcs_counts, min_frequency=100):\n",
    "    filtered_items = [(subseq, freq) for subseq, freq in fcs_counts.items() if freq >= min_frequency]\n",
    "    filtered_items.sort(key=lambda x: x[1], reverse=True)\n",
    "    data = []\n",
    "    for rank, (subseq, freq) in enumerate(filtered_items, start=1):\n",
    "        data.append({\"Subsequence\": subseq, \"Frequency\": freq, \"Rank\": rank})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Process drug SMILES FCS if not already done\n",
    "drug_output_file = DRUG_FCS_CSV\n",
    "if not os.path.exists(drug_output_file):\n",
    "    df_drug = pd.read_csv(DRUGBANK_CSV)\n",
    "    smiles_column = \"smiles\"\n",
    "    if smiles_column not in df_drug.columns:\n",
    "        raise ValueError(f\"No '{smiles_column}' column found in {DRUGBANK_CSV}!\")\n",
    "    smiles_list = df_drug[smiles_column].dropna().astype(str).tolist()\n",
    "    print(\"Extracting subsequences from drug SMILES...\")\n",
    "    smiles_fcs_counts = extract_fcs_subsequences_stream(\n",
    "        smiles_list, min_length=2, max_length=10,\n",
    "        prune_every=1000, prune_threshold=5, preserve_short_length=5\n",
    "    )\n",
    "    smiles_fcs_df = filter_and_rank_fcs(smiles_fcs_counts, min_frequency=5)\n",
    "    smiles_fcs_df.to_csv(drug_output_file, index=False)\n",
    "    print(f\"[DRUG SMILES] Total subsequences (frequency ≥ 5): {len(smiles_fcs_df)}\")\n",
    "else:\n",
    "    print(f\"{drug_output_file} already exists. Skipping drug SMILES subsequence extraction.\")\n",
    "\n",
    "# Process protein sequences FCS similarly\n",
    "protein_output_file = PROTEIN_FCS_CSV\n",
    "if not os.path.exists(protein_output_file):\n",
    "    df_protein = pd.read_csv(PROTEIN_CSV)\n",
    "    protein_column = \"sequence\"\n",
    "    if protein_column not in df_protein.columns:\n",
    "        raise ValueError(f\"No '{protein_column}' column found in {PROTEIN_CSV}!\")\n",
    "    protein_list = df_protein[protein_column].dropna().astype(str).tolist()\n",
    "    print(\"Extracting subsequences from protein sequences...\")\n",
    "    protein_fcs_counts = extract_fcs_subsequences_stream(\n",
    "        protein_list, min_length=2, max_length=10,\n",
    "        prune_every=1000, prune_threshold=5, preserve_short_length=5\n",
    "    )\n",
    "    protein_fcs_df = filter_and_rank_fcs(protein_fcs_counts, min_frequency=5)\n",
    "    protein_fcs_df.to_csv(protein_output_file, index=False)\n",
    "    print(f\"[PROTEIN] Total subsequences (frequency ≥ 5): {len(protein_fcs_df)}\")\n",
    "else:\n",
    "    print(f\"{protein_output_file} already exists. Skipping protein sequences subsequence extraction.\")\n",
    "\n",
    "# --- (B) Encoding ---\n",
    "def encode_sequence(seq, token_dict, min_subseq_len=2):\n",
    "    return [token_dict.get(seq[i:j], 0)\n",
    "            for i in range(len(seq))\n",
    "            for j in range(i + min_subseq_len, len(seq) + 1)]\n",
    "\n",
    "drug_df = pd.read_csv(DRUGBANK_CSV)\n",
    "protein_df = pd.read_csv(PROTEIN_CSV)\n",
    "drug_dict_df = pd.read_csv(drug_output_file)\n",
    "protein_dict_df = pd.read_csv(protein_output_file)\n",
    "import json\n",
    "if not os.path.exists(DRUG_ENCODED_CSV) or not os.path.exists(PROTEIN_ENCODED_CSV):\n",
    "    drug_token_dict = dict(zip(drug_dict_df[\"Subsequence\"], drug_dict_df[\"Rank\"]))\n",
    "    protein_token_dict = dict(zip(protein_dict_df[\"Subsequence\"], protein_dict_df[\"Rank\"]))\n",
    "    drug_df[\"Encoded\"] = drug_df[\"smiles\"].apply(lambda x: encode_sequence(str(x), drug_token_dict, min_subseq_len=2))\n",
    "    protein_df[\"Encoded\"] = protein_df[\"sequence\"].apply(lambda x: encode_sequence(str(x), protein_token_dict, min_subseq_len=2))\n",
    "    drug_df.to_csv(DRUG_ENCODED_CSV, index=False)\n",
    "    protein_df.to_csv(PROTEIN_ENCODED_CSV, index=False)\n",
    "else:\n",
    "    print(f\"{DRUG_ENCODED_CSV} and {PROTEIN_ENCODED_CSV} already exist. Skipping encoding step.\")\n",
    "\n",
    "# --- (C) Merging Encoded Data with Interaction Labels ---\n",
    "drug_encoded_df = pd.read_csv(DRUG_ENCODED_CSV)\n",
    "protein_encoded_df = pd.read_csv(PROTEIN_ENCODED_CSV)\n",
    "# Make sure to use the proper key names (e.g., \"Drug id\" and \"pdb_id\")\n",
    "pdb_drug_map = pd.read_csv(INTERACTIONS_CSV)\n",
    "pdb_drug_map.to_csv(INTERACTIONS_CSV, index=False)\n",
    "\n",
    "pdb_drug_map.rename(columns={'Drug ID': 'Drug id', 'PDB ID': 'pdb_id'}, inplace=True)\n",
    "print(pdb_drug_map.head())\n",
    "confirmed_interactions = pd.read_csv(INTERACTIONS_CSV)\n",
    "drug_encodings = pd.read_csv(DRUG_ENCODED_CSV)\n",
    "protein_encodings = pd.read_csv(PROTEIN_ENCODED_CSV)\n",
    "# Rename columns in confirmed_interactions for consistency (if needed)\n",
    "\n",
    "\n",
    "\n",
    "def gen_neg_samples(confirmed_interactions):\n",
    "    \"\"\"\n",
    "    Generate negative samples for drug-target interactions\n",
    "    \n",
    "    Args:\n",
    "        confirmed_interactions: DataFrame with columns ['Drug id', 'pdb_id']\n",
    "    Returns:\n",
    "        DataFrame with negative samples\n",
    "    \"\"\"\n",
    "    unique_prots = confirmed_interactions[\"pdb_id\"].unique()\n",
    "    unique_drugs = confirmed_interactions[\"Drug id\"].unique()\n",
    "    \n",
    "    # Convert confirmed interactions to set for faster lookup\n",
    "    confirmed_pairs = set(zip(confirmed_interactions[\"Drug id\"], \n",
    "                            confirmed_interactions[\"pdb_id\"]))\n",
    "    \n",
    "    # Number of negative samples to generate (2x positive samples)\n",
    "    n_samples = len(confirmed_interactions) * 1\n",
    "    neg_samples = []\n",
    "    \n",
    "    with tqdm(total=n_samples, desc=\"Generating negative samples\") as pbar:\n",
    "        while len(neg_samples) < n_samples:\n",
    "            drug = random.choice(unique_drugs)\n",
    "            prot = random.choice(unique_prots)\n",
    "            \n",
    "            # Check if this pair is not in confirmed interactions\n",
    "            if (drug, prot) not in confirmed_pairs:\n",
    "                neg_samples.append([drug, prot])\n",
    "                pbar.update(1)\n",
    "    print(len(neg_samples))\n",
    "    print(len(confirmed_pairs))\n",
    "    return pd.DataFrame(neg_samples, columns=[\"Drug id\", \"pdb_id\"])\n",
    "\n",
    "\n",
    "# Rename columns in confirmed_interactions for consistency (if needed)\n",
    "confirmed_interactions.rename(columns={'Drug ID': 'Drug id', 'PDB ID': 'pdb_id'}, inplace=True)\n",
    "\n",
    "\n",
    "neg_inter = gen_neg_samples(confirmed_interactions)\n",
    "print(neg_inter.head())\n",
    "\n",
    "confirmed_interactions['label'] = 1\n",
    "neg_inter['label'] = 0\n",
    "\n",
    "# Combine positive and negative samples\n",
    "confirmed_interactions = pd.concat([confirmed_interactions, neg_inter], ignore_index=True)\n",
    "print(\"Confirmed\")\n",
    "confirmed_interactions = confirmed_interactions.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(confirmed_interactions.head())\n",
    "# Merge on common identifiers (assuming columns \"Drug id\" and \"pdb_id\")\n",
    "merged_df = pdb_drug_map.merge(drug_encoded_df, on='Drug id', how='inner')\n",
    "merged_df = merged_df.merge(protein_encoded_df, on='pdb_id', how='inner')\n",
    "\n",
    "if not os.path.exists(MERGED_ENCODING_CSV):\n",
    "    merged_df.to_csv(MERGED_ENCODING_CSV, index=False)\n",
    "    print(f\"File {MERGED_ENCODING_CSV} created.\")\n",
    "else:\n",
    "    print(f\"File {MERGED_ENCODING_CSV} already exists. Skipping save.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Association Rule Mining for DTI Prediction\n",
    "\n",
    "- For association rule mining we only need the interaction information.\n",
    "- We use the confirmed interactions from the merged file.\n",
    "- (Assume merged_df contains columns: \"Drug id\", \"pdb_id\", and \"label\")\n",
    "- If your merged_df contains extra encoded columns, we ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Transaction Matrix:\n",
      "pdb_id   12CA  1A02  1A07  1A28  1A31  1A3Q  1A52  1A5H  1A85  1AB2  ...  \\\n",
      "Drug id                                                              ...   \n",
      "DB00131     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00148     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00159     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00182     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00191     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "\n",
      "pdb_id   4MQE  4MZ2  4RED  4V11  4WUR  4Z9M  4ZK4  5CFB  5UWI  6A69  \n",
      "Drug id                                                              \n",
      "DB00131     0     0     1     0     0     0     0     0     0     0  \n",
      "DB00148     0     0     0     0     0     0     0     0     0     0  \n",
      "DB00159     0     0     0     0     0     0     0     0     0     0  \n",
      "DB00182     0     0     0     0     0     0     0     0     0     0  \n",
      "DB00191     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 229 columns]\n",
      "\n",
      "Test Transaction Matrix (first 5 rows):\n",
      "pdb_id   12CA  1A07  1A0N  1A27  1A28  1A2C  1A52  1A5K  1AB2  1AGW  ...  \\\n",
      "Drug id                                                              ...   \n",
      "DB00140     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00148     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00159     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00193     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "DB00201     0     0     0     0     0     0     0     0     0     0  ...   \n",
      "\n",
      "pdb_id   4MQE  4MZ2  4OON  4PHU  4R3D  4TWK  4V11  4Z9M  5UWI  6A69  \n",
      "Drug id                                                              \n",
      "DB00140     0     0     0     0     0     0     0     0     0     0  \n",
      "DB00148     0     0     0     0     0     0     0     1     0     0  \n",
      "DB00159     0     0     0     1     0     0     0     0     0     0  \n",
      "DB00193     0     0     0     0     0     0     0     0     0     0  \n",
      "DB00201     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 180 columns]\n",
      "Mined Association Rules:\n",
      "     antecedents   consequents   support  confidence       lift\n",
      "0         (12CA)        (1AZM)  0.011278    0.500000  19.000000\n",
      "1         (1AZM)        (12CA)  0.011278    0.428571  19.000000\n",
      "2         (12CA)        (1ZNC)  0.015038    0.666667  44.333333\n",
      "3         (1ZNC)        (12CA)  0.015038    1.000000  44.333333\n",
      "4         (1BSX)        (1NAV)  0.011278    1.000000  88.666667\n",
      "..           ...           ...       ...         ...        ...\n",
      "85  (2WAD, 2C5W)        (2UWX)  0.022556    0.857143  19.000000\n",
      "86  (2UWX, 2C5W)        (2WAD)  0.022556    0.750000  22.166667\n",
      "87        (2WAD)  (2UWX, 2C5W)  0.022556    0.666667  22.166667\n",
      "88        (2UWX)  (2WAD, 2C5W)  0.022556    0.500000  19.000000\n",
      "89        (2C5W)  (2WAD, 2UWX)  0.022556    0.545455  20.727273\n",
      "\n",
      "[90 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f3/kgkwlzhd025fqwv56bs8t87m0000gn/T/ipykernel_70689/3093107305.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  trans = trans.applymap(lambda x: 1 if x >= 1 else 0)\n",
      "/var/folders/f3/kgkwlzhd025fqwv56bs8t87m0000gn/T/ipykernel_70689/3093107305.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  trans = trans.applymap(lambda x: 1 if x >= 1 else 0)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interactions = confirmed_interactions[['Drug id', 'pdb_id', 'label']].copy()\n",
    "\n",
    "# Split into training and test sets (by rows)\n",
    "train_interactions, test_interactions = train_test_split(interactions, test_size=0.4, random_state=42)\n",
    "\n",
    "def build_transaction_matrix(df):\n",
    "    \"\"\"Build binary transaction matrix for positive interactions.\"\"\"\n",
    "    pos_df = df[df['label'] == 1]\n",
    "    trans = pos_df.pivot_table(index='Drug id', columns='pdb_id', aggfunc='size', fill_value=0)\n",
    "    trans = trans.applymap(lambda x: 1 if x >= 1 else 0)\n",
    "    return trans\n",
    "\n",
    "# Build training transaction matrix\n",
    "train_matrix = build_transaction_matrix(train_interactions)\n",
    "print(\"Training Transaction Matrix:\")\n",
    "print(train_matrix.head())\n",
    "\n",
    "\n",
    "test_matrix = build_transaction_matrix(test_interactions)\n",
    "print(\"\\nTest Transaction Matrix (first 5 rows):\")\n",
    "print(test_matrix.head())\n",
    "\n",
    "# Mine frequent itemsets and association rules\n",
    "min_support = 0.01  # Adjust as needed\n",
    "min_confidence = 0.3\n",
    "frequent_itemsets = apriori(train_matrix, min_support=min_support, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "print(\"Mined Association Rules:\")\n",
    "if not rules.empty:\n",
    "    print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "else:\n",
    "    print(\"No rules mined with current thresholds.\")\n",
    "\n",
    "def predict_dti(drug_id, protein_id, transaction_matrix, rules, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Predict DTI using association rules.\n",
    "    \n",
    "    For a given drug, if the set of proteins it interacts with (from training) \n",
    "    supports the candidate protein via one or more mined rules, then output 1, \n",
    "    else 0. Also return the average confidence of matching rules.\n",
    "    \"\"\"\n",
    "    if drug_id not in transaction_matrix.index:\n",
    "        return 0, 0.0\n",
    "    known_proteins = set(transaction_matrix.columns[transaction_matrix.loc[drug_id] == 1])\n",
    "    matching = rules[\n",
    "        rules['antecedents'].apply(lambda x: x.issubset(known_proteins)) &\n",
    "        rules['consequents'].apply(lambda x: protein_id in x)\n",
    "    ]\n",
    "    if matching.empty:\n",
    "        return 0, 0.0\n",
    "    avg_conf = matching['confidence'].mean()\n",
    "    pred = 1 if avg_conf >= confidence_threshold else 0\n",
    "    return pred, avg_conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rule Mining Evaluation Metrics:\n",
      "{'accuracy': 0.4993548387096774, 'confusion_matrix': array([[379,   0],\n",
      "       [388,   8]]), 'roc_auc': 0.6313131313131313, 'pr_auc': 0.8197002280873248}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Plot Confusion Matrix\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     32\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m], annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m             xticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], yticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Label\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(test_df, transaction_matrix, rules, confidence_threshold=0.7):\n",
    "    preds, confs, trues = [], [], []\n",
    "    for _, row in test_df.iterrows():\n",
    "        d_id = row['Drug id']\n",
    "        p_id = row['pdb_id']\n",
    "        true_label = row['label']\n",
    "        pred, conf = predict_dti(d_id, p_id, transaction_matrix, rules, confidence_threshold)\n",
    "        preds.append(pred)\n",
    "        confs.append(conf)\n",
    "        trues.append(true_label)\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    cm = confusion_matrix(trues, preds)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(trues, confs)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    precision, recall, _ = precision_recall_curve(trues, confs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc\n",
    "    }\n",
    "\n",
    "metrics = evaluate_model(test_interactions, train_matrix, rules, confidence_threshold=0.7)\n",
    "print(\"\\nAssociation Rule Mining Evaluation Metrics:\")\n",
    "print(metrics)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(metrics[\"confusion_matrix\"], annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# For ROC and PR curves, first extract the prediction confidence values from test data.\n",
    "def get_evaluation_data(test_df, transaction_matrix, rules, confidence_threshold=0.7):\n",
    "    preds, confs, trues = [], [], []\n",
    "    for _, row in test_df.iterrows():\n",
    "        d_id = row['Drug id']\n",
    "        p_id = row['pdb_id']\n",
    "        true_label = row['label']\n",
    "        pred, conf = predict_dti(d_id, p_id, transaction_matrix, rules, confidence_threshold)\n",
    "        preds.append(pred)\n",
    "        confs.append(conf)\n",
    "        trues.append(true_label)\n",
    "    return np.array(trues), np.array(confs), np.array(preds)\n",
    "\n",
    "trues, confs, preds = get_evaluation_data(test_interactions, train_matrix, rules, confidence_threshold=0.7)\n",
    "\n",
    "# ROC Curve (if both classes exist)\n",
    "if np.any(trues == 0) and np.any(trues == 1):\n",
    "    fpr, tpr, _ = roc_curve(trues, confs, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guess\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC Curve cannot be plotted because one of the classes is missing in the test set.\")\n",
    "\n",
    "# Precision-Recall Curve\n",
    "if np.any(trues == 1):\n",
    "    precision, recall, _ = precision_recall_curve(trues, confs, pos_label=1)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f\"Precision-Recall Curve (AUC = {pr_auc:.4f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Precision-Recall Curve cannot be plotted because there are no positive samples in the test set.\")\n",
    "\n",
    "###############################################\n",
    "# Part 5: Example Prediction on a Test Pair\n",
    "###############################################\n",
    "\n",
    "example_row = test_interactions.iloc[0]\n",
    "ex_drug = example_row['Drug id']\n",
    "ex_prot = example_row['pdb_id']\n",
    "pred, conf = predict_dti(ex_drug, ex_prot, train_matrix, rules, confidence_threshold=0.5)\n",
    "print(f\"\\nExample Prediction for Drug {ex_drug} and Protein {ex_prot}:\")\n",
    "print(f\"Predicted Label: {pred}, Average Rule Confidence: {conf:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
