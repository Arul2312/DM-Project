{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:34.509324Z",
     "iopub.status.busy": "2025-03-30T03:15:34.509077Z",
     "iopub.status.idle": "2025-03-30T03:15:42.984413Z",
     "shell.execute_reply": "2025-03-30T03:15:42.983615Z",
     "shell.execute_reply.started": "2025-03-30T03:15:34.509304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating negative pairs: 100%|██████████| 968/968 [00:00<00:00, 716949.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive pairs: 968\n",
      "Number of negative pairs: 968\n",
      "Sample of negative pairs:\n",
      "[('DB08877', '1F0J', 0), ('DB13269', '3OC2', 0), ('DB09195', '1L2J', 0), ('DB13955', '3UVJ', 0), ('DB01073', '1YRK', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Load data (example structure)\n",
    "drugs = pd.read_csv(\"drug_smiles.csv\")  # {Drug ID: SMILES}\n",
    "proteins = pd.read_csv(\"pdb_sequences.csv\")  # {PDB ID: Sequence}\n",
    "interactions = pd.read_csv(\"confirmed_interactions.csv\")  # {PDB ID: [Drug IDs]}\n",
    "\n",
    "drugs_dict = drugs.set_index('Drug id')['smiles'].to_dict()  # Assuming these are your column names\n",
    "proteins_dict = proteins.set_index('pdb_id')['sequence'].to_dict()\n",
    "\n",
    "# Create dataset\n",
    "drug_ids = list(drugs_dict.keys())\n",
    "protein_ids = list(proteins_dict.keys())\n",
    "\n",
    "positive_pairs = []\n",
    "for _, row in interactions.iterrows():\n",
    "        drug_id = row['Drug ID']  # Adjust column name if different\n",
    "        pdb_id = row['PDB ID']    # Adjust column name if different\n",
    "        \n",
    "        # Verify the pair exists in our dictionaries\n",
    "        if drug_id in drugs_dict and pdb_id in proteins_dict:\n",
    "            positive_pairs.append((drug_id, pdb_id, 1))\n",
    "\n",
    "# Create negative pairs more efficiently\n",
    "negative_pairs = []\n",
    "used_pairs = set((d, p) for d, p, _ in positive_pairs)\n",
    "num_needed = len(positive_pairs)\n",
    "\n",
    "# Use batch processing with progress tracking\n",
    "from tqdm import tqdm\n",
    "batch_size = 1000\n",
    "\n",
    "with tqdm(total=num_needed, desc=\"Generating negative pairs\") as pbar:\n",
    "    while len(negative_pairs) < num_needed:\n",
    "        # Generate multiple pairs at once\n",
    "        batch_drugs = random.choices(drug_ids, k=batch_size)\n",
    "        batch_proteins = random.choices(protein_ids, k=batch_size)\n",
    "        \n",
    "        for d, p in zip(batch_drugs, batch_proteins):\n",
    "            if (d, p) not in used_pairs:\n",
    "                negative_pairs.append((d, p, 0))\n",
    "                used_pairs.add((d, p))\n",
    "                pbar.update(1)\n",
    "                \n",
    "                if len(negative_pairs) >= num_needed:\n",
    "                    break\n",
    "\n",
    "# Verify the results\n",
    "print(f\"Number of positive pairs: {len(interactions)}\")\n",
    "print(f\"Number of negative pairs: {len(negative_pairs)}\")\n",
    "print(f\"Sample of negative pairs:\\n{negative_pairs[:5]}\")\n",
    "dataset = positive_pairs + negative_pairs\n",
    "random.shuffle(dataset)\n",
    "\n",
    "# Split dataset (train/val/test as per paper: ~70/15/15)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "train_data, val_data, test_data = dataset[:train_size], dataset[train_size:train_size + val_size], dataset[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:48.614884Z",
     "iopub.status.busy": "2025-03-30T03:15:48.614638Z",
     "iopub.status.idle": "2025-03-30T03:15:48.621257Z",
     "shell.execute_reply": "2025-03-30T03:15:48.620457Z",
     "shell.execute_reply.started": "2025-03-30T03:15:48.614864Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:48.622411Z",
     "iopub.status.busy": "2025-03-30T03:15:48.622169Z",
     "iopub.status.idle": "2025-03-30T03:15:48.726688Z",
     "shell.execute_reply": "2025-03-30T03:15:48.726119Z",
     "shell.execute_reply.started": "2025-03-30T03:15:48.622380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load subsequence CSVs\n",
    "drug_subseq_df = pd.read_csv(\"drug_smiles_fcs_freq_100.csv\")  # e.g., columns: subsequence, rank\n",
    "protein_subseq_df = pd.read_csv(\"protein_fcs_freq_100.csv\")\n",
    "\n",
    "# Build dictionaries\n",
    "drug_vocab = dict(zip(drug_subseq_df[\"Subsequence\"], drug_subseq_df[\"Rank\"]))\n",
    "protein_vocab = dict(zip(protein_subseq_df[\"Subsequence\"], protein_subseq_df[\"Rank\"]))\n",
    "\n",
    "# Combine into single vocab with special tokens\n",
    "vocab = {\"[CLS]\": 0, \"[SEP]\": 1, \"[MASK]\": 2, \"[PAD]\": 3, \"[UNK]\": 4}\n",
    "vocab.update(drug_vocab)\n",
    "# Fixed iteration over protein_vocab items\n",
    "for subseq, rank in protein_vocab.items():  # Use .items() to iterate over key-value pairs\n",
    "    if subseq not in vocab:\n",
    "        vocab[subseq] = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:48.727624Z",
     "iopub.status.busy": "2025-03-30T03:15:48.727421Z",
     "iopub.status.idle": "2025-03-30T03:15:48.732221Z",
     "shell.execute_reply": "2025-03-30T03:15:48.731488Z",
     "shell.execute_reply.started": "2025-03-30T03:15:48.727607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50507"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:48.734609Z",
     "iopub.status.busy": "2025-03-30T03:15:48.734369Z",
     "iopub.status.idle": "2025-03-30T03:15:48.760828Z",
     "shell.execute_reply": "2025-03-30T03:15:48.759962Z",
     "shell.execute_reply.started": "2025-03-30T03:15:48.734590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "drugs = pd.read_csv(\"drug_smiles.csv\").set_index(\"Drug id\")[\"smiles\"].to_dict()  # {Drug ID: SMILES}\n",
    "proteins = pd.read_csv(\"pdb_sequences.csv\").set_index(\"pdb_id\")[\"sequence\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:48.762599Z",
     "iopub.status.busy": "2025-03-30T03:15:48.762302Z",
     "iopub.status.idle": "2025-03-30T03:15:48.766948Z",
     "shell.execute_reply": "2025-03-30T03:15:48.766348Z",
     "shell.execute_reply.started": "2025-03-30T03:15:48.762569Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building subsequence representations...\n",
      "Processed 300 drugs and 298 proteins\n",
      "\n",
      "Sample drug subsequences: ['Nc', 'c1', '1n', 'nc', 'cn']\n",
      "Sample protein subsequences: ['RH', 'HV', 'VR', 'RI', 'IK']\n"
     ]
    }
   ],
   "source": [
    "def get_matching_subsequences(sequence, vocab_subset, min_len=2, max_len=6):\n",
    "    \"\"\"Extract subsequences from a sequence that match the vocabulary\"\"\"\n",
    "    subsequences = []\n",
    "    \n",
    "    for length in range(min_len, min(max_len + 1, len(sequence) + 1)):\n",
    "        for i in range(len(sequence) - length + 1):\n",
    "            subseq = sequence[i:i + length]\n",
    "            if subseq in vocab_subset:\n",
    "                subsequences.append(subseq)\n",
    "    \n",
    "    # If no subsequences found, use special token\n",
    "    if not subsequences:\n",
    "        subsequences.append(\"[UNK]\")\n",
    "        \n",
    "    return subsequences\n",
    "\n",
    "# Process all sequences and build subsequence representations\n",
    "print(\"Building subsequence representations...\")\n",
    "drug_representations = {}  # {drug_id: [subsequences]}\n",
    "protein_representations = {}  # {pdb_id: [subsequences]}\n",
    "\n",
    "for drug_id in drugs_dict:\n",
    "    drug_seq = drugs_dict[drug_id]\n",
    "    drug_representations[drug_id] = get_matching_subsequences(drug_seq, drug_vocab)\n",
    "\n",
    "for pdb_id in proteins_dict:\n",
    "    protein_seq = proteins_dict[pdb_id]\n",
    "    protein_representations[pdb_id] = get_matching_subsequences(protein_seq, protein_vocab)\n",
    "\n",
    "print(f\"Processed {len(drug_representations)} drugs and {len(protein_representations)} proteins\")\n",
    "\n",
    "# Sample output\n",
    "print(\"\\nSample drug subsequences:\", next(iter(drug_representations.values()))[:5])\n",
    "print(\"Sample protein subsequences:\", next(iter(protein_representations.values()))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:50.667200Z",
     "iopub.status.busy": "2025-03-30T03:15:50.666944Z",
     "iopub.status.idle": "2025-03-30T03:15:50.740819Z",
     "shell.execute_reply": "2025-03-30T03:15:50.740156Z",
     "shell.execute_reply.started": "2025-03-30T03:15:50.667180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DTISubsequenceTokenizer:\n",
    "    \"\"\"Wrapper around base tokenizer with subsequence-specific processing\"\"\"\n",
    "    \n",
    "    def __init__(self, base_tokenizer):\n",
    "        self.tokenizer = base_tokenizer\n",
    "        \n",
    "        # Add special tokens for subsequence processing\n",
    "        special_tokens = {\n",
    "            \"additional_special_tokens\": [\"[SUB]\"]\n",
    "        }\n",
    "        \n",
    "        # Add the tokens to the tokenizer\n",
    "        num_added = self.tokenizer.add_special_tokens(special_tokens)\n",
    "        print(f\"Added {num_added} special tokens to the tokenizer\")\n",
    "        \n",
    "        # Store token IDs for quick access\n",
    "        self.sub_token_id = self.tokenizer.convert_tokens_to_ids(\"[SUB]\")\n",
    "        self.sep_token_id = self.tokenizer.sep_token_id\n",
    "        self.cls_token_id = self.tokenizer.cls_token_id\n",
    "        self.pad_token_id = self.tokenizer.pad_token_id\n",
    "        \n",
    "    def __call__(self, drug_text, protein_text, **kwargs):\n",
    "        \"\"\"Tokenize drug and protein texts with special handling for subsequences\"\"\"\n",
    "        # Format input with special tokens\n",
    "        text_pair = f\"{drug_text}\", f\"{protein_text}\"\n",
    "        \n",
    "        # Use the base tokenizer\n",
    "        encoding = self.tokenizer(\n",
    "            text_pair[0],\n",
    "            text_pair[1],\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        \"\"\"Convert token IDs back to string tokens\"\"\"\n",
    "        return self.tokenizer.convert_ids_to_tokens(ids)\n",
    "    \n",
    "    def batch_encode_plus(self, batch_text_pairs, **kwargs):\n",
    "        \"\"\"Batch encode multiple text pairs\"\"\"\n",
    "        return self.tokenizer.batch_encode_plus(batch_text_pairs, **kwargs)\n",
    "    \n",
    "    # Forward all other methods to the base tokenizer\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.tokenizer, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in /home/f20221129/.conda/envs/torch/lib/python3.10/site-packages (2024.9.6)\n",
      "Requirement already satisfied: numpy in /home/f20221129/.conda/envs/torch/lib/python3.10/site-packages (from rdkit) (2.2.3)\n",
      "Requirement already satisfied: Pillow in /home/f20221129/.conda/envs/torch/lib/python3.10/site-packages (from rdkit) (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:50.741899Z",
     "iopub.status.busy": "2025-03-30T03:15:50.741601Z",
     "iopub.status.idle": "2025-03-30T03:15:58.873257Z",
     "shell.execute_reply": "2025-03-30T03:15:58.872542Z",
     "shell.execute_reply.started": "2025-03-30T03:15:50.741867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MACCSkeys\n",
    "\n",
    "class SubsequenceProcessor:\n",
    "    \"\"\"Extract meaningful subsequences from drugs and proteins\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define common protein motifs and drug functional groups for matching\n",
    "        self.protein_motifs = {\n",
    "            'zinc_finger': r'C.{2,4}C.{3}[LIVMFYWC].{8}H.{3,5}H',\n",
    "            'helix_turn_helix': r'[LIVMFYW].{2}[LIVMF].{8,10}[LIVMFYWC].{5}[LIVMF]',\n",
    "            'binding_pocket': r'[RK].{2,4}[DE].{2,4}[RK]',\n",
    "            'hydrophobic': r'[LIVMFYW]{3,}',\n",
    "            'acidic': r'[DE]{2,}',\n",
    "            'basic': r'[RK]{2,}',\n",
    "            'phosphorylation': r'[ST]P',\n",
    "            'glycosylation': r'N[^P][ST]'\n",
    "        }\n",
    "        \n",
    "        # Common drug functional groups\n",
    "        self.drug_functional_groups = [\n",
    "            'C(=O)N',     # Amide\n",
    "            'c1ccccc1',   # Benzene\n",
    "            'C(=O)O',     # Carboxyl\n",
    "            'CN',         # Amine\n",
    "            'CO',         # Alcohol\n",
    "            'C=O',        # Carbonyl\n",
    "            'CS',         # Thiol\n",
    "            'CF',         # Fluoro\n",
    "            'CCl',        # Chloro\n",
    "            'CBr',        # Bromo\n",
    "            'CI',         # Iodo\n",
    "            'C=C',        # Alkene\n",
    "            'C#N',        # Nitrile\n",
    "            'C#C',        # Alkyne\n",
    "            'N=O',        # Nitro\n",
    "            'c1ccncc1',   # Pyridine\n",
    "            'c1cncnc1',   # Pyrimidine\n",
    "            'c1cnccn1',   # Pyrazine\n",
    "            'c1cnncc1',   # Pyridazine\n",
    "        ]\n",
    "    \n",
    "    def extract_protein_subsequences(self, sequence, window_size=8, stride=4):\n",
    "        \"\"\"Extract protein subsequences using sliding window and motif matching\"\"\"\n",
    "        subsequences = []\n",
    "        \n",
    "        # Add the whole sequence as a subsequence if it's short\n",
    "        if len(sequence) <= window_size * 2:\n",
    "            subsequences.append(sequence)\n",
    "            return subsequences\n",
    "            \n",
    "        # Use sliding window to extract subsequences\n",
    "        for i in range(0, len(sequence) - window_size + 1, stride):\n",
    "            subsequences.append(sequence[i:i+window_size])\n",
    "        \n",
    "        # Extract known motifs using regex patterns\n",
    "        for motif_name, pattern in self.protein_motifs.items():\n",
    "            for match in re.finditer(pattern, sequence):\n",
    "                motif_seq = match.group(0)\n",
    "                if motif_seq not in subsequences:\n",
    "                    subsequences.append(motif_seq)\n",
    "        \n",
    "        return subsequences\n",
    "    \n",
    "    def extract_drug_subsequences(self, smiles):\n",
    "        \"\"\"Extract meaningful subsequences from drug SMILES string\"\"\"\n",
    "        subsequences = []\n",
    "        \n",
    "        # Add the original SMILES as a subsequence if it's short\n",
    "        if len(smiles) < 20:\n",
    "            subsequences.append(smiles)\n",
    "        \n",
    "        try:\n",
    "            # Parse the SMILES string\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                # If parsing fails, return the original SMILES broken into chunks\n",
    "                return [smiles[i:i+10] for i in range(0, len(smiles), 10)]\n",
    "            \n",
    "            # Get Morgan fingerprint as representation of functional groups\n",
    "            fp = AllChem.GetMorganFingerprint(mol, 2)\n",
    "            for bit_id, _ in fp.GetNonzeroElements().items():\n",
    "                env = Chem.MolToSmiles(AllChem.GetMorganEnvFragment(mol, bit_id, 1))\n",
    "                if env and len(env) <= 20:  # Reasonable size for a subsequence\n",
    "                    subsequences.append(env)\n",
    "            \n",
    "            # Check for presence of common functional groups\n",
    "            for fg in self.drug_functional_groups:\n",
    "                patt = Chem.MolFromSmiles(fg)\n",
    "                if mol.HasSubstructMatch(patt):\n",
    "                    subsequences.append(fg)\n",
    "                    \n",
    "            # Extract ring systems\n",
    "            for ring in Chem.GetSymmSSSR(mol):\n",
    "                ring_smiles = Chem.MolToSmiles(Chem.PathToSubmol(mol, list(ring)))\n",
    "                if ring_smiles and ring_smiles not in subsequences:\n",
    "                    subsequences.append(ring_smiles)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            # If chemical parsing fails, use simple string-based chunking\n",
    "            print(f\"Error processing SMILES {smiles}: {str(e)}\")\n",
    "            subsequences = [smiles[i:i+10] for i in range(0, len(smiles), 10)]\n",
    "        \n",
    "        # Ensure we have at least some subsequences\n",
    "        if not subsequences:\n",
    "            subsequences = [smiles]\n",
    "            \n",
    "        return subsequences\n",
    "\n",
    "class EnhancedDTIDataset(Dataset):\n",
    "    def __init__(self, pairs, drugs_dict, proteins_dict, tokenizer, config):\n",
    "        self.pairs = pairs\n",
    "        self.drugs_dict = drugs_dict\n",
    "        self.proteins_dict = proteins_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "        \n",
    "        # Process sequences in advance\n",
    "        self.processed_data = []\n",
    "        \n",
    "        print(\"Pre-processing drug-protein pairs...\")\n",
    "        for drug_id, pdb_id, label in tqdm(pairs, desc=\"Processing dataset\"):\n",
    "            if drug_id in drugs_dict and pdb_id in proteins_dict:\n",
    "                # Get SMILES and protein sequence\n",
    "                smiles = drugs_dict[drug_id]\n",
    "                sequence = proteins_dict[pdb_id]\n",
    "                \n",
    "                # Process sequences (add methods to extract subsequences if needed)\n",
    "                processed_drug = self.process_drug(smiles)\n",
    "                processed_protein = self.process_protein(sequence)\n",
    "                \n",
    "                # Tokenize with special tokens\n",
    "                encoding = self.tokenize_pair(processed_drug, processed_protein)\n",
    "                \n",
    "                # Store processed data\n",
    "                item = {\n",
    "                    'drug_id': drug_id,\n",
    "                    'pdb_id': pdb_id,\n",
    "                    'input_ids': encoding['input_ids'],\n",
    "                    'attention_mask': encoding['attention_mask'],\n",
    "                    'token_type_ids': encoding.get('token_type_ids', None),\n",
    "                    'labels': torch.tensor(label, dtype=torch.long)\n",
    "                }\n",
    "                \n",
    "                self.processed_data.append(item)\n",
    "        \n",
    "        print(f\"Processed {len(self.processed_data)} valid drug-protein pairs.\")\n",
    "    \n",
    "    def process_drug(self, smiles):\n",
    "        \"\"\"Process drug SMILES string - can be enhanced with RDKit\"\"\"\n",
    "        return smiles\n",
    "    \n",
    "    def process_protein(self, sequence):\n",
    "        \"\"\"Process protein sequence - can be enhanced with motif detection\"\"\"\n",
    "        return sequence\n",
    "    \n",
    "    def tokenize_pair(self, drug, protein):\n",
    "        \"\"\"Tokenize drug-protein pair with appropriate special tokens\"\"\"\n",
    "        # Format input with special tokens\n",
    "        text_pair = (\n",
    "            f\"{drug}\",\n",
    "            f\"{protein}\"\n",
    "        )\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text_pair[0],\n",
    "            text_pair[1],\n",
    "            padding='max_length',\n",
    "            truncation='longest_first',\n",
    "            max_length=self.config.max_seq_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        for key in encoding:\n",
    "            if isinstance(encoding[key], torch.Tensor):\n",
    "                encoding[key] = encoding[key].squeeze(0)\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.processed_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:58.880406Z",
     "iopub.status.busy": "2025-03-30T03:15:58.880087Z",
     "iopub.status.idle": "2025-03-30T03:15:58.915525Z",
     "shell.execute_reply": "2025-03-30T03:15:58.914886Z",
     "shell.execute_reply.started": "2025-03-30T03:15:58.880377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "def initialize_weights(module):\n",
    "    \"\"\"Initialize transformer weights properly\"\"\"\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        # Slightly different initialization from PyTorch as BioBERT is from transformers\n",
    "        module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "\n",
    "class DTITransformerModel(nn.Module):\n",
    "    def __init__(self, config, tokenizer):\n",
    "        super(DTITransformerModel, self).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # BioBERT encoder for initial embeddings\n",
    "        self.bert = AutoModel.from_pretrained(\n",
    "            \"dmis-lab/biobert-v1.1\",\n",
    "            add_pooling_layer=False,\n",
    "            output_attentions=True\n",
    "        )\n",
    "        \n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # Freeze BioBERT parameters except last N layers\n",
    "        unfreeze_layers = 2  # Last 2 layers\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            # Unfreeze specified layers\n",
    "            if any(f\"encoder.layer.{str(11-i)}.\" in name for i in range(unfreeze_layers)):\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Positional embeddings\n",
    "        self.position_embeddings = nn.Embedding(config.max_seq_length, hidden_size)\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_seq_length).expand((1, -1)))\n",
    "        \n",
    "        # Drug-protein type embeddings\n",
    "        self.type_embeddings = nn.Embedding(2, hidden_size)\n",
    "        \n",
    "        # Layer normalization and dropout\n",
    "        self.LayerNorm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(config.dropout_rate)\n",
    "        \n",
    "        # Transformer encoder (6 layers, 12 heads as per paper)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=config.num_attention_heads,\n",
    "            dim_feedforward=config.intermediate_size,\n",
    "            dropout=config.dropout_rate,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=config.num_encoder_layers\n",
    "        )\n",
    "        \n",
    "        # FC layer (384 units as per paper)\n",
    "        self.intermediate_dense = nn.Linear(hidden_size, config.fc_size)\n",
    "        \n",
    "        # Output classification layer\n",
    "        self.classifier = nn.Linear(config.fc_size, config.num_classes)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self.apply(initialize_weights)\n",
    "        \n",
    "        # Count trainable parameters\n",
    "        self.num_parameters = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f\"Trainable parameters: {self.num_parameters:,}\")\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, return_attentions=False):\n",
    "        \"\"\"Forward pass with improved stability\"\"\"\n",
    "        # Get token embeddings from BioBERT\n",
    "        with torch.set_grad_enabled(True):  # Ensure gradients even with frozen layers\n",
    "            bert_outputs = self.bert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_attentions=return_attentions\n",
    "            )\n",
    "        \n",
    "        token_embeddings = bert_outputs.last_hidden_state\n",
    "        \n",
    "        # Add positional embeddings\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = self.position_ids[:, :seq_length]\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Create drug-protein type IDs\n",
    "        batch_size = input_ids.size(0)\n",
    "        drug_protein_type_ids = torch.zeros_like(input_ids)\n",
    "        \n",
    "        # Use the tokenizer's sep_token_id for robustness\n",
    "        sep_token_id = self.tokenizer.sep_token_id if hasattr(self.tokenizer, 'sep_token_id') else 102\n",
    "        \n",
    "        # Find drug-protein boundaries using [SEP] tokens\n",
    "        for i in range(batch_size):\n",
    "            sep_positions = (input_ids[i] == sep_token_id).nonzero(as_tuple=True)[0]\n",
    "            if len(sep_positions) >= 1:\n",
    "                first_sep = sep_positions[0]\n",
    "                drug_protein_type_ids[i, first_sep+1:] = 1\n",
    "        \n",
    "        # Get type embeddings\n",
    "        type_embeddings = self.type_embeddings(drug_protein_type_ids)\n",
    "        \n",
    "        # Combine embeddings \n",
    "        embeddings = token_embeddings + position_embeddings + type_embeddings\n",
    "        \n",
    "        # Apply layer norm and dropout\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        # Apply attention mask for transformer\n",
    "        transformer_mask = attention_mask.float()\n",
    "        transformer_mask = transformer_mask.masked_fill(transformer_mask == 0, float('-inf'))\n",
    "        transformer_mask = transformer_mask.masked_fill(transformer_mask == 1, float(0.0))\n",
    "        \n",
    "        # Pass through transformer encoder with proper masking\n",
    "        transformer_outputs = self.transformer_encoder(embeddings, src_key_padding_mask=(attention_mask == 0))\n",
    "        \n",
    "        # Extract [CLS] token representation for classification\n",
    "        cls_output = transformer_outputs[:, 0]\n",
    "        \n",
    "        # Apply intermediate FC layer\n",
    "        intermediate_output = self.intermediate_dense(cls_output)\n",
    "        intermediate_output = F.gelu(intermediate_output)\n",
    "        intermediate_output = self.dropout(intermediate_output)\n",
    "        \n",
    "        # Final classification\n",
    "        logits = self.classifier(intermediate_output)\n",
    "        \n",
    "        if return_attentions:\n",
    "            return logits, bert_outputs.attentions\n",
    "        \n",
    "        return logits\n",
    "        \n",
    "# Model configuration\n",
    "class ModelConfig:\n",
    "    def __init__(self):\n",
    "        # Model architecture - Section 2.5.4\n",
    "        self.hidden_size = 768           # BioBERT base hidden size\n",
    "        self.intermediate_size = 1536    # \"intermediate dimension of 1536\"\n",
    "        self.num_attention_heads = 12    # \"12 attention heads to each encoder\" \n",
    "        self.num_encoder_layers = 6      # \"six hidden transformer encoder layers\"\n",
    "        self.fc_size = 384              # \"the size of the final network of the FC layer is 384\"\n",
    "        \n",
    "        # Model parameters\n",
    "        self.num_classes = 2            # Binary classification\n",
    "        self.max_seq_length = 512       # Maximum sequence length for tokenization\n",
    "        \n",
    "        # Subsequence parameters\n",
    "        self.max_drug_subseqs = 20      # Maximum number of drug subsequences to use\n",
    "        self.max_protein_subseqs = 40   # Maximum number of protein subsequences to use\n",
    "        self.use_subseq_markers = True  # Whether to use subsequence marker tokens\n",
    "        \n",
    "        # Training parameters from the paper\n",
    "        self.batch_size = 32            # \"batch size... to 32\"\n",
    "        self.num_epochs = 100           # \"number of epochs to 100\" \n",
    "        self.learning_rate = 1e-5       # \"learning rate... 1e-5\"\n",
    "        self.dropout_rate = 0.1         # \"dropout rate are... 0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:58.916550Z",
     "iopub.status.busy": "2025-03-30T03:15:58.916356Z",
     "iopub.status.idle": "2025-03-30T03:15:58.934567Z",
     "shell.execute_reply": "2025-03-30T03:15:58.933626Z",
     "shell.execute_reply.started": "2025-03-30T03:15:58.916525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, config, train_loader, val_loader, device):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize class weights for imbalance\n",
    "        self.class_weights = self.compute_class_weights()\n",
    "        self.class_weights = torch.tensor(self.class_weights, dtype=torch.float).to(device)\n",
    "        \n",
    "        # Loss function with focal loss for imbalanced data\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        \n",
    "        # Optimizer with weight decay and different LR for different parameter groups\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() \n",
    "                          if not any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "                \"weight_decay\": 0.01,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() \n",
    "                          if any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=config.learning_rate,\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # LR scheduler with warmup\n",
    "        total_steps = len(train_loader) * config.num_epochs\n",
    "        warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
    "        \n",
    "        from transformers import get_scheduler\n",
    "        self.scheduler = get_scheduler(\n",
    "            name=\"linear\",\n",
    "            optimizer=self.optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        # Save training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'train_accuracy': [],\n",
    "            'val_accuracy': [],\n",
    "            'train_f1': [],\n",
    "            'val_f1': [],\n",
    "            'val_auc': []\n",
    "        }\n",
    "        \n",
    "        # Best model state\n",
    "        self.best_model_state = None\n",
    "        self.best_val_f1 = 0.0\n",
    "    \n",
    "    def compute_class_weights(self):\n",
    "        \"\"\"Compute weights for class imbalance\"\"\"\n",
    "        # Count samples per class\n",
    "        class_counts = [0, 0]  # Binary classification\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "            for label, count in zip(unique_labels, counts):\n",
    "                class_counts[label] += count\n",
    "        \n",
    "        # Calculate balanced weights\n",
    "        total = sum(class_counts)\n",
    "        weights = [total / (len(class_counts) * count) if count > 0 else 1.0 \n",
    "                  for count in class_counts]\n",
    "        \n",
    "        print(f\"Class counts: {class_counts}\")\n",
    "        print(f\"Class weights: {weights}\")\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch with stability improvements\"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        train_iter = tqdm(self.train_loader, desc=f\"Training Epoch {epoch+1}/{self.config.num_epochs}\")\n",
    "        \n",
    "        for batch in train_iter:\n",
    "            # Move to device\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Handle potential CUDA out of memory\n",
    "            try:\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass with gradient clipping\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                \n",
    "                # Collect metrics\n",
    "                epoch_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                train_iter.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{(preds == labels).float().mean().item():.4f}\",\n",
    "                    'lr': f\"{self.scheduler.get_last_lr()[0]:.8f}\"\n",
    "                })\n",
    "            \n",
    "            except RuntimeError as e:\n",
    "                if 'out of memory' in str(e):\n",
    "                    print(f\"WARNING: CUDA OOM - Skipping batch and reducing batch size\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        metrics = self.calculate_metrics(all_preds, all_labels, epoch_loss, len(self.train_loader))\n",
    "        \n",
    "        # Update history\n",
    "        self.history['train_loss'].append(metrics['loss'])\n",
    "        self.history['train_accuracy'].append(metrics['accuracy'])\n",
    "        self.history['train_f1'].append(metrics['f1'])\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        \"\"\"Validate model on validation set\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        \n",
    "        val_pbar = tqdm(self.val_loader, desc=f'Validation Epoch {epoch+1}/{self.config.num_epochs}')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_pbar:\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                token_type_ids = batch.get('token_type_ids', None)\n",
    "                if token_type_ids is not None:\n",
    "                    token_type_ids = token_type_ids.to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Calculate probabilities for positive class\n",
    "                probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "                \n",
    "                # Track metrics\n",
    "                total_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{(preds == labels).float().mean().item():.4f}\"\n",
    "                })\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self.calculate_metrics(all_preds, all_labels, total_loss, len(self.val_loader))\n",
    "        \n",
    "        # Add AUC if we have both classes in validation set\n",
    "        unique_labels = np.unique(all_labels)\n",
    "        if len(unique_labels) > 1:\n",
    "            metrics['auc'] = roc_auc_score(all_labels, all_probs)\n",
    "        \n",
    "        # Track history\n",
    "        self.history['val_loss'].append(metrics['loss'])\n",
    "        self.history['val_accuracy'].append(metrics['accuracy'])\n",
    "        self.history['val_f1'].append(metrics['f1'])\n",
    "        \n",
    "        # Print detailed validation results\n",
    "        self.print_validation_stats(all_preds, all_labels, metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def calculate_metrics(self, preds, labels, total_loss, num_batches):\n",
    "        \"\"\"Calculate evaluation metrics\"\"\"\n",
    "        # Handle case with only one class\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) <= 1:\n",
    "            if 1 in unique_labels:  # Only positive samples\n",
    "                precision = 1.0\n",
    "                recall = 1.0\n",
    "                f1 = 1.0\n",
    "            else:  # Only negative samples\n",
    "                precision = 0.0\n",
    "                recall = 0.0\n",
    "                f1 = 0.0\n",
    "        else:\n",
    "            precision = precision_score(labels, preds, zero_division=0)\n",
    "            recall = recall_score(labels, preds, zero_division=0)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        \n",
    "        # Create metrics dictionary\n",
    "        return {\n",
    "            'loss': total_loss / num_batches,\n",
    "            'accuracy': accuracy_score(labels, preds),\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "    \n",
    "    def print_validation_stats(self, preds, labels, metrics):\n",
    "        \"\"\"Print validation statistics\"\"\"\n",
    "        # Print prediction distribution\n",
    "        unique_preds, counts = np.unique(preds, return_counts=True)\n",
    "        pred_distribution = {int(label): int(count) for label, count in zip(unique_preds, counts)}\n",
    "        print(f\"\\nPrediction Distribution: {pred_distribution}\")\n",
    "        \n",
    "        # Print confusion matrix if possible\n",
    "        if len(np.unique(labels)) > 1 and len(np.unique(preds)) > 1:\n",
    "            cm = confusion_matrix(labels, preds)\n",
    "            print(\"\\nConfusion Matrix:\")\n",
    "            print(cm)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(\"\\nValidation Metrics:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Main training loop with early stopping\"\"\"\n",
    "        best_val_f1 = 0.0\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        print(f\"Starting training for {self.config.num_epochs} epochs...\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters() if p.requires_grad):,} trainable\")\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            print(f'\\nEpoch {epoch+1}/{self.config.num_epochs}')\n",
    "            \n",
    "            # Training phase\n",
    "            train_metrics = self.train_epoch(epoch)\n",
    "            print(\"\\nTraining Metrics:\")\n",
    "            for metric, value in train_metrics.items():\n",
    "                print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "            \n",
    "            # Validation phase\n",
    "            val_metrics = self.validate(epoch)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if val_metrics['f1'] > best_val_f1:\n",
    "                best_val_f1 = val_metrics['f1']\n",
    "                patience_counter = 0\n",
    "                print(f'\\nNew best F1 score: {best_val_f1:.4f} - saving model')\n",
    "                \n",
    "                # Save best model\n",
    "                best_model_state = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                    'best_f1': best_val_f1,\n",
    "                    'config': self.config.__dict__,\n",
    "                    'history': self.history\n",
    "                }\n",
    "                torch.save(best_model_state, 'best_dti_model.pt')\n",
    "            # else:\n",
    "            #     patience_counter += 1\n",
    "            #     print(f'\\nNo improvement in F1 score. Patience: {patience_counter}/{patience}')\n",
    "                \n",
    "            #     if patience_counter >= patience:\n",
    "            #         print(f'\\nEarly stopping triggered after {epoch+1} epochs')\n",
    "            #         break\n",
    "        \n",
    "        # Load best model if available\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state['model_state_dict'])\n",
    "            print(f\"\\nLoaded best model from epoch {best_model_state['epoch']+1}\")\n",
    "        \n",
    "        print(\"\\nTraining completed!\")\n",
    "        print(f\"Best validation F1 score: {best_val_f1:.4f}\")\n",
    "        \n",
    "        # Plot training history\n",
    "        self.plot_training_history()\n",
    "        \n",
    "        return best_val_f1\n",
    "    \n",
    "    def evaluate_test_set(self, test_loader):\n",
    "        \"\"\"Evaluate model on test set\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        all_drug_ids = []\n",
    "        all_pdb_ids = []\n",
    "        \n",
    "        print(\"\\nEvaluating on test set...\")\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Test Evaluation\"):\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                token_type_ids = batch.get('token_type_ids', None)\n",
    "                if token_type_ids is not None:\n",
    "                    token_type_ids = token_type_ids.to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                # Store drug and pdb IDs\n",
    "                all_drug_ids.extend(batch['drug_id'])\n",
    "                all_pdb_ids.extend(batch['pdb_id'])\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Calculate probabilities\n",
    "                probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "                \n",
    "                # Track metrics\n",
    "                total_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self.calculate_metrics(all_preds, all_labels, total_loss, len(test_loader))\n",
    "        \n",
    "        # Add AUC if we have both classes\n",
    "        unique_labels = np.unique(all_labels)\n",
    "        if len(unique_labels) > 1:\n",
    "            metrics['auc'] = roc_auc_score(all_labels, all_probs)\n",
    "        \n",
    "        # Print test results\n",
    "        print(\"\\nTest Set Confusion Matrix:\")\n",
    "        print(confusion_matrix(all_labels, all_preds))\n",
    "        \n",
    "        print(\"\\nTest Set Metrics:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        # Save detailed results for analysis\n",
    "        results = pd.DataFrame({\n",
    "            'drug_id': all_drug_ids,\n",
    "            'pdb_id': all_pdb_ids,\n",
    "            'true_label': all_labels,\n",
    "            'predicted': all_preds,\n",
    "            'probability': all_probs\n",
    "        })\n",
    "        \n",
    "        results.to_csv('test_predictions.csv', index=False)\n",
    "        print(\"Saved detailed test predictions to 'test_predictions.csv'\")\n",
    "        \n",
    "        return metrics, results\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            # Create figure with subplots\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            \n",
    "            # Plot loss\n",
    "            ax1.plot(self.history['train_loss'], label='Training Loss')\n",
    "            ax1.plot(self.history['val_loss'], label='Validation Loss')\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('Training and Validation Loss')\n",
    "            ax1.legend()\n",
    "            \n",
    "            # Plot metrics\n",
    "            ax2.plot(self.history['train_acc'], label='Training Accuracy')\n",
    "            ax2.plot(self.history['val_acc'], label='Validation Accuracy')\n",
    "            ax2.plot(self.history['train_f1'], label='Training F1')\n",
    "            ax2.plot(self.history['val_f1'], label='Validation F1')\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('Score')\n",
    "            ax2.set_title('Training and Validation Metrics')\n",
    "            ax2.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('training_history.png')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Training history plot saved to 'training_history.png'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot training history: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Set seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def initialize_training():\n",
    "    \"\"\"Initialize all components with stability improvements\"\"\"\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    print(\"Loading BioBERT tokenizer...\")\n",
    "    base_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "    \n",
    "    # Initialize model configuration\n",
    "    print(\"Creating model configuration...\")\n",
    "    config = ModelConfig()\n",
    "    \n",
    "    # Create datasets with enhanced preprocessing\n",
    "    print(\"Creating datasets...\")\n",
    "    train_dataset = EnhancedDTIDataset(\n",
    "        train_data,\n",
    "        drugs_dict,\n",
    "        proteins_dict,\n",
    "        base_tokenizer,\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    val_dataset = EnhancedDTIDataset(\n",
    "        val_data,\n",
    "        drugs_dict,\n",
    "        proteins_dict,\n",
    "        base_tokenizer,\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    test_dataset = EnhancedDTIDataset(\n",
    "        test_data,\n",
    "        drugs_dict,\n",
    "        proteins_dict,\n",
    "        base_tokenizer,\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    print(\"Creating data loaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,  # Improves transfer speed to GPU\n",
    "        drop_last=True    # Important for stable batch norm\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"Initializing DTI Transformer model...\")\n",
    "    model = DTITransformerModel(config, base_tokenizer)\n",
    "    \n",
    "    # Move model to device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create trainer\n",
    "    print(\"Creating trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        config=config,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return model, trainer, test_loader, test_dataset, base_tokenizer, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:15:58.935968Z",
     "iopub.status.busy": "2025-03-30T03:15:58.935470Z",
     "iopub.status.idle": "2025-03-30T03:16:26.750951Z",
     "shell.execute_reply": "2025-03-30T03:16:26.749514Z",
     "shell.execute_reply.started": "2025-03-30T03:15:58.935936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BioBERT tokenizer...\n",
      "Creating model configuration...\n",
      "Creating datasets...\n",
      "Pre-processing drug-protein pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 1355/1355 [00:00<00:00, 1643.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1355 valid drug-protein pairs.\n",
      "Pre-processing drug-protein pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 290/290 [00:00<00:00, 1599.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 290 valid drug-protein pairs.\n",
      "Pre-processing drug-protein pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 291/291 [00:00<00:00, 1579.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 291 valid drug-protein pairs.\n",
      "Creating data loaders...\n",
      "Initializing DTI Transformer model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dmis-lab/biobert-v1.1 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 43,230,338\n",
      "Using device: cuda\n",
      "Creating trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [np.int64(696), np.int64(648)]\n",
      "Class weights: [np.float64(0.9655172413793104), np.float64(1.037037037037037)]\n",
      "Starting training for 100 epochs...\n",
      "Model parameters: 43,230,338 trainable\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 1/100: 100%|██████████| 42/42 [00:20<00:00,  2.04it/s, loss=0.6995, acc=0.4062, lr=0.00000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6988\n",
      "Accuracy: 0.4955\n",
      "Precision: 0.4350\n",
      "Recall: 0.1495\n",
      "F1: 0.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/f20221129/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Validation Epoch 1/100: 100%|██████████| 10/10 [00:02<00:00,  4.99it/s, loss=0.7780, acc=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 282, 1: 8}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[132   1]\n",
      " [150   7]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7054\n",
      "Accuracy: 0.4793\n",
      "Precision: 0.8750\n",
      "Recall: 0.0446\n",
      "F1: 0.0848\n",
      "Auc: 0.5454\n",
      "\n",
      "New best F1 score: 0.0848 - saving model\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 2/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7063, acc=0.4062, lr=0.00000200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6931\n",
      "Accuracy: 0.5126\n",
      "Precision: 0.4913\n",
      "Recall: 0.4388\n",
      "F1: 0.4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 2/100: 100%|██████████| 10/10 [00:01<00:00,  5.07it/s, loss=0.6879, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 28, 1: 262}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 12 121]\n",
      " [ 16 141]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6882\n",
      "Accuracy: 0.5276\n",
      "Precision: 0.5382\n",
      "Recall: 0.8981\n",
      "F1: 0.6730\n",
      "Auc: 0.5515\n",
      "\n",
      "New best F1 score: 0.6730 - saving model\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 3/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6798, acc=0.5625, lr=0.00000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6964\n",
      "Accuracy: 0.5030\n",
      "Precision: 0.4803\n",
      "Recall: 0.3957\n",
      "F1: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 3/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 3/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.6994, acc=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 171, 1: 119}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[81 52]\n",
      " [90 67]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6923\n",
      "Accuracy: 0.5103\n",
      "Precision: 0.5630\n",
      "Recall: 0.4268\n",
      "F1: 0.4855\n",
      "Auc: 0.5506\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 4/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6687, acc=0.5312, lr=0.00000400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6897\n",
      "Accuracy: 0.5171\n",
      "Precision: 0.5000\n",
      "Recall: 0.5593\n",
      "F1: 0.5280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 4/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 4/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.7561, acc=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 287, 1: 3}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[133   0]\n",
      " [154   3]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7129\n",
      "Accuracy: 0.4690\n",
      "Precision: 1.0000\n",
      "Recall: 0.0191\n",
      "F1: 0.0375\n",
      "Auc: 0.5452\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 5/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6844, acc=0.5625, lr=0.00000500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6915\n",
      "Accuracy: 0.5246\n",
      "Precision: 0.5092\n",
      "Recall: 0.5084\n",
      "F1: 0.5088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 5/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 5/100: 100%|██████████| 10/10 [00:01<00:00,  5.07it/s, loss=0.6675, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 206, 1: 84}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 98  35]\n",
      " [108  49]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6947\n",
      "Accuracy: 0.5069\n",
      "Precision: 0.5833\n",
      "Recall: 0.3121\n",
      "F1: 0.4066\n",
      "Auc: 0.5452\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 6/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6621, acc=0.6875, lr=0.00000600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6886\n",
      "Accuracy: 0.5454\n",
      "Precision: 0.5234\n",
      "Recall: 0.6053\n",
      "F1: 0.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 6/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 6/100: 100%|██████████| 10/10 [00:01<00:00,  5.07it/s, loss=0.4845, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 41, 1: 249}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 21 112]\n",
      " [ 20 137]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6657\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.5502\n",
      "Recall: 0.8726\n",
      "F1: 0.6749\n",
      "Auc: 0.5458\n",
      "\n",
      "New best F1 score: 0.6749 - saving model\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 7/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6493, acc=0.6875, lr=0.00000700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6880\n",
      "Accuracy: 0.5432\n",
      "Precision: 0.5252\n",
      "Recall: 0.5170\n",
      "F1: 0.5211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 7/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 7/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.5350, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 124, 1: 166}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[60 73]\n",
      " [64 93]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6767\n",
      "Accuracy: 0.5276\n",
      "Precision: 0.5602\n",
      "Recall: 0.5924\n",
      "F1: 0.5759\n",
      "Auc: 0.5444\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 8/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6576, acc=0.5938, lr=0.00000800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6794\n",
      "Accuracy: 0.5737\n",
      "Precision: 0.5530\n",
      "Recall: 0.6034\n",
      "F1: 0.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 8/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 8/100: 100%|██████████| 10/10 [00:01<00:00,  5.03it/s, loss=0.5953, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 213, 1: 77}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[102  31]\n",
      " [111  46]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7082\n",
      "Accuracy: 0.5103\n",
      "Precision: 0.5974\n",
      "Recall: 0.2930\n",
      "F1: 0.3932\n",
      "Auc: 0.5534\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 9/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6666, acc=0.6250, lr=0.00000900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6845\n",
      "Accuracy: 0.5618\n",
      "Precision: 0.5443\n",
      "Recall: 0.5502\n",
      "F1: 0.5473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 9/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 9/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4698, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 133, 1: 157}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[67 66]\n",
      " [66 91]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6730\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.5796\n",
      "Recall: 0.5796\n",
      "F1: 0.5796\n",
      "Auc: 0.5539\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 10/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6671, acc=0.6250, lr=0.00001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6793\n",
      "Accuracy: 0.5744\n",
      "Precision: 0.5557\n",
      "Recall: 0.5712\n",
      "F1: 0.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 10/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 10/100: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, loss=0.4970, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 169, 1: 121}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85 48]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6866\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6033\n",
      "Recall: 0.4650\n",
      "F1: 0.5252\n",
      "Auc: 0.5512\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 11/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6589, acc=0.6250, lr=0.00000989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6873\n",
      "Accuracy: 0.5618\n",
      "Precision: 0.5452\n",
      "Recall: 0.5578\n",
      "F1: 0.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 11/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 11/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.5332, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 175, 1: 115}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[88 45]\n",
      " [87 70]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6855\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6087\n",
      "Recall: 0.4459\n",
      "F1: 0.5147\n",
      "Auc: 0.5556\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 12/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6942, acc=0.5000, lr=0.00000978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6797\n",
      "Accuracy: 0.5618\n",
      "Precision: 0.5419\n",
      "Recall: 0.5978\n",
      "F1: 0.5685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 12/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 12/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.3782, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 69, 1: 221}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 36  97]\n",
      " [ 33 124]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6583\n",
      "Accuracy: 0.5517\n",
      "Precision: 0.5611\n",
      "Recall: 0.7898\n",
      "F1: 0.6561\n",
      "Auc: 0.5554\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 13/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6786, acc=0.4688, lr=0.00000967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6789\n",
      "Accuracy: 0.5625\n",
      "Precision: 0.5450\n",
      "Recall: 0.5602\n",
      "F1: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 13/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 13/100: 100%|██████████| 10/10 [00:01<00:00,  5.03it/s, loss=0.3753, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 105, 1: 185}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 55  78]\n",
      " [ 50 107]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6623\n",
      "Accuracy: 0.5586\n",
      "Precision: 0.5784\n",
      "Recall: 0.6815\n",
      "F1: 0.6257\n",
      "Auc: 0.5612\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 14/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6641, acc=0.6562, lr=0.00000956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6752\n",
      "Accuracy: 0.5848\n",
      "Precision: 0.5664\n",
      "Recall: 0.5926\n",
      "F1: 0.5792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 14/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 14/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.6269, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 241, 1: 49}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[116  17]\n",
      " [125  32]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7315\n",
      "Accuracy: 0.5103\n",
      "Precision: 0.6531\n",
      "Recall: 0.2038\n",
      "F1: 0.3107\n",
      "Auc: 0.5641\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 15/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6484, acc=0.7188, lr=0.00000944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6769\n",
      "Accuracy: 0.5707\n",
      "Precision: 0.5481\n",
      "Recall: 0.6317\n",
      "F1: 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 15/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 15/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.3868, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 116, 1: 174}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62  71]\n",
      " [ 54 103]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6639\n",
      "Accuracy: 0.5690\n",
      "Precision: 0.5920\n",
      "Recall: 0.6561\n",
      "F1: 0.6224\n",
      "Auc: 0.5643\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 16/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6479, acc=0.6562, lr=0.00000933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6766\n",
      "Accuracy: 0.5774\n",
      "Precision: 0.5587\n",
      "Recall: 0.5743\n",
      "F1: 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 16/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 16/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.4005, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 133, 1: 157}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[69 64]\n",
      " [64 93]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6648\n",
      "Accuracy: 0.5586\n",
      "Precision: 0.5924\n",
      "Recall: 0.5924\n",
      "F1: 0.5924\n",
      "Auc: 0.5654\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 17/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6732, acc=0.5000, lr=0.00000922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6781\n",
      "Accuracy: 0.5662\n",
      "Precision: 0.5505\n",
      "Recall: 0.5240\n",
      "F1: 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 17/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 17/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4120, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 95, 1: 195}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 45  88]\n",
      " [ 50 107]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6593\n",
      "Accuracy: 0.5241\n",
      "Precision: 0.5487\n",
      "Recall: 0.6815\n",
      "F1: 0.6080\n",
      "Auc: 0.5631\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 18/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6601, acc=0.6875, lr=0.00000911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6763\n",
      "Accuracy: 0.5826\n",
      "Precision: 0.5642\n",
      "Recall: 0.6015\n",
      "F1: 0.5823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 18/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 18/100: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, loss=0.2667, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 14, 1: 276}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  8 125]\n",
      " [  6 151]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6693\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.5471\n",
      "Recall: 0.9618\n",
      "F1: 0.6975\n",
      "Auc: 0.5599\n",
      "\n",
      "New best F1 score: 0.6975 - saving model\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 19/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6455, acc=0.6562, lr=0.00000900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6840\n",
      "Accuracy: 0.5446\n",
      "Precision: 0.5269\n",
      "Recall: 0.5432\n",
      "F1: 0.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 19/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 19/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.4883, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 151, 1: 139}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[77 56]\n",
      " [74 83]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6714\n",
      "Accuracy: 0.5517\n",
      "Precision: 0.5971\n",
      "Recall: 0.5287\n",
      "F1: 0.5608\n",
      "Auc: 0.5626\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 20/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6096, acc=0.6562, lr=0.00000889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6739\n",
      "Accuracy: 0.5729\n",
      "Precision: 0.5562\n",
      "Recall: 0.5648\n",
      "F1: 0.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 20/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 20/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5092, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 198, 1: 92}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 95  38]\n",
      " [103  54]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6952\n",
      "Accuracy: 0.5138\n",
      "Precision: 0.5870\n",
      "Recall: 0.3439\n",
      "F1: 0.4337\n",
      "Auc: 0.5633\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 21/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.7001, acc=0.5312, lr=0.00000878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6766\n",
      "Accuracy: 0.5811\n",
      "Precision: 0.5739\n",
      "Recall: 0.5200\n",
      "F1: 0.5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 21/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 21/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.4526, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 176, 1: 114}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89 44]\n",
      " [87 70]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6865\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.6140\n",
      "Recall: 0.4459\n",
      "F1: 0.5166\n",
      "Auc: 0.5646\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 22/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6363, acc=0.6562, lr=0.00000867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6734\n",
      "Accuracy: 0.5826\n",
      "Precision: 0.5623\n",
      "Recall: 0.5997\n",
      "F1: 0.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 22/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 22/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5063, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 220, 1: 70}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  24]\n",
      " [111  46]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7048\n",
      "Accuracy: 0.5345\n",
      "Precision: 0.6571\n",
      "Recall: 0.2930\n",
      "F1: 0.4053\n",
      "Auc: 0.5685\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 23/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7415, acc=0.5000, lr=0.00000856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6819\n",
      "Accuracy: 0.5677\n",
      "Precision: 0.5539\n",
      "Recall: 0.5309\n",
      "F1: 0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 23/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 23/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5820, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 221, 1: 69}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[108  25]\n",
      " [113  44]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7202\n",
      "Accuracy: 0.5241\n",
      "Precision: 0.6377\n",
      "Recall: 0.2803\n",
      "F1: 0.3894\n",
      "Auc: 0.5662\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 24/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6410, acc=0.5938, lr=0.00000844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6760\n",
      "Accuracy: 0.5900\n",
      "Precision: 0.5678\n",
      "Recall: 0.6161\n",
      "F1: 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 24/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 24/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4980, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 184, 1: 106}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91 42]\n",
      " [93 64]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6889\n",
      "Accuracy: 0.5345\n",
      "Precision: 0.6038\n",
      "Recall: 0.4076\n",
      "F1: 0.4867\n",
      "Auc: 0.5649\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 25/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7582, acc=0.5000, lr=0.00000833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6736\n",
      "Accuracy: 0.5871\n",
      "Precision: 0.5757\n",
      "Recall: 0.5607\n",
      "F1: 0.5681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 25/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 25/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.3085, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 88, 1: 202}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 45  88]\n",
      " [ 43 114]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6550\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.5644\n",
      "Recall: 0.7261\n",
      "F1: 0.6351\n",
      "Auc: 0.5652\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 26/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6607, acc=0.5312, lr=0.00000822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6720\n",
      "Accuracy: 0.5856\n",
      "Precision: 0.5655\n",
      "Recall: 0.5944\n",
      "F1: 0.5796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 26/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 26/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4278, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 165, 1: 125}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[84 49]\n",
      " [81 76]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6731\n",
      "Accuracy: 0.5517\n",
      "Precision: 0.6080\n",
      "Recall: 0.4841\n",
      "F1: 0.5390\n",
      "Auc: 0.5658\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 27/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6683, acc=0.5312, lr=0.00000811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6770\n",
      "Accuracy: 0.5878\n",
      "Precision: 0.5679\n",
      "Recall: 0.6065\n",
      "F1: 0.5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 27/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 27/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4971, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 193, 1: 97}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95 38]\n",
      " [98 59]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6963\n",
      "Accuracy: 0.5310\n",
      "Precision: 0.6082\n",
      "Recall: 0.3758\n",
      "F1: 0.4646\n",
      "Auc: 0.5641\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 28/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7289, acc=0.5000, lr=0.00000800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6737\n",
      "Accuracy: 0.5945\n",
      "Precision: 0.5803\n",
      "Recall: 0.5741\n",
      "F1: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 28/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 28/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.4622, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 189, 1: 101}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95 38]\n",
      " [94 63]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6910\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6238\n",
      "Recall: 0.4013\n",
      "F1: 0.4884\n",
      "Auc: 0.5687\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 29/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.5734, acc=0.8438, lr=0.00000789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6685\n",
      "Accuracy: 0.5856\n",
      "Precision: 0.5723\n",
      "Recall: 0.5609\n",
      "F1: 0.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 29/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 29/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4948, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 193, 1: 97}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[96 37]\n",
      " [97 60]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6927\n",
      "Accuracy: 0.5379\n",
      "Precision: 0.6186\n",
      "Recall: 0.3822\n",
      "F1: 0.4724\n",
      "Auc: 0.5675\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 30/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6663, acc=0.6250, lr=0.00000778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6753\n",
      "Accuracy: 0.5826\n",
      "Precision: 0.5646\n",
      "Recall: 0.5985\n",
      "F1: 0.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 30/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 30/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.3746, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 142, 1: 148}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[73 60]\n",
      " [69 88]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6702\n",
      "Accuracy: 0.5552\n",
      "Precision: 0.5946\n",
      "Recall: 0.5605\n",
      "F1: 0.5770\n",
      "Auc: 0.5644\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 31/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6309, acc=0.6875, lr=0.00000767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6669\n",
      "Accuracy: 0.5952\n",
      "Precision: 0.5791\n",
      "Recall: 0.5969\n",
      "F1: 0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 31/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 31/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5302, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 214, 1: 76}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105  28]\n",
      " [109  48]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7114\n",
      "Accuracy: 0.5276\n",
      "Precision: 0.6316\n",
      "Recall: 0.3057\n",
      "F1: 0.4120\n",
      "Auc: 0.5674\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 32/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7049, acc=0.6250, lr=0.00000756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6682\n",
      "Accuracy: 0.6176\n",
      "Precision: 0.6301\n",
      "Recall: 0.5039\n",
      "F1: 0.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 32/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 32/100: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, loss=0.2784, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 89, 1: 201}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 45  88]\n",
      " [ 44 113]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6587\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.5622\n",
      "Recall: 0.7197\n",
      "F1: 0.6313\n",
      "Auc: 0.5640\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 33/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6377, acc=0.5625, lr=0.00000744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6859\n",
      "Accuracy: 0.5625\n",
      "Precision: 0.5399\n",
      "Recall: 0.6364\n",
      "F1: 0.5842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 33/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 33/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.6845, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 267, 1: 23}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[126   7]\n",
      " [141  16]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7645\n",
      "Accuracy: 0.4897\n",
      "Precision: 0.6957\n",
      "Recall: 0.1019\n",
      "F1: 0.1778\n",
      "Auc: 0.5701\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 34/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6884, acc=0.5625, lr=0.00000733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6732\n",
      "Accuracy: 0.5923\n",
      "Precision: 0.5871\n",
      "Recall: 0.5201\n",
      "F1: 0.5516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 34/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 34/100: 100%|██████████| 10/10 [00:01<00:00,  5.03it/s, loss=0.3954, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 155, 1: 135}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[81 52]\n",
      " [74 83]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6771\n",
      "Accuracy: 0.5655\n",
      "Precision: 0.6148\n",
      "Recall: 0.5287\n",
      "F1: 0.5685\n",
      "Auc: 0.5634\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 35/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7123, acc=0.5312, lr=0.00000722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6663\n",
      "Accuracy: 0.5982\n",
      "Precision: 0.5740\n",
      "Recall: 0.6466\n",
      "F1: 0.6081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 35/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 35/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4719, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 203, 1: 87}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 99  34]\n",
      " [104  53]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7203\n",
      "Accuracy: 0.5241\n",
      "Precision: 0.6092\n",
      "Recall: 0.3376\n",
      "F1: 0.4344\n",
      "Auc: 0.5666\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 36/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.7220, acc=0.5000, lr=0.00000711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6647\n",
      "Accuracy: 0.6004\n",
      "Precision: 0.5862\n",
      "Recall: 0.5652\n",
      "F1: 0.5755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 36/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 36/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.3643, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 113, 1: 177}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53 80]\n",
      " [60 97]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6646\n",
      "Accuracy: 0.5172\n",
      "Precision: 0.5480\n",
      "Recall: 0.6178\n",
      "F1: 0.5808\n",
      "Auc: 0.5618\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 37/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7030, acc=0.5000, lr=0.00000700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6610\n",
      "Accuracy: 0.6042\n",
      "Precision: 0.5931\n",
      "Recall: 0.5785\n",
      "F1: 0.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 37/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 37/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.3605, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 154, 1: 136}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[80 53]\n",
      " [74 83]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6768\n",
      "Accuracy: 0.5621\n",
      "Precision: 0.6103\n",
      "Recall: 0.5287\n",
      "F1: 0.5666\n",
      "Auc: 0.5610\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 38/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6714, acc=0.5312, lr=0.00000689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6572\n",
      "Accuracy: 0.6131\n",
      "Precision: 0.5967\n",
      "Recall: 0.6133\n",
      "F1: 0.6049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 38/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 38/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5062, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 230, 1: 60}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  24]\n",
      " [121  36]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7261\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.6000\n",
      "Recall: 0.2293\n",
      "F1: 0.3318\n",
      "Auc: 0.5638\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 39/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6967, acc=0.7500, lr=0.00000678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6576\n",
      "Accuracy: 0.6190\n",
      "Precision: 0.6143\n",
      "Recall: 0.5573\n",
      "F1: 0.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 39/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 39/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4692, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 213, 1: 77}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[102  31]\n",
      " [111  46]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7096\n",
      "Accuracy: 0.5103\n",
      "Precision: 0.5974\n",
      "Recall: 0.2930\n",
      "F1: 0.3932\n",
      "Auc: 0.5589\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 40/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6675, acc=0.5938, lr=0.00000667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6486\n",
      "Accuracy: 0.6131\n",
      "Precision: 0.6026\n",
      "Recall: 0.5765\n",
      "F1: 0.5893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 40/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 40/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.4209, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 190, 1: 100}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[93 40]\n",
      " [97 60]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7057\n",
      "Accuracy: 0.5276\n",
      "Precision: 0.6000\n",
      "Recall: 0.3822\n",
      "F1: 0.4669\n",
      "Auc: 0.5583\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 41/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6113, acc=0.7188, lr=0.00000656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6455\n",
      "Accuracy: 0.6220\n",
      "Precision: 0.6160\n",
      "Recall: 0.5800\n",
      "F1: 0.5975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 41/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 41/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.3615, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 177, 1: 113}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89 44]\n",
      " [88 69]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6941\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6106\n",
      "Recall: 0.4395\n",
      "F1: 0.5111\n",
      "Auc: 0.5627\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 42/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7363, acc=0.4688, lr=0.00000644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6528\n",
      "Accuracy: 0.6205\n",
      "Precision: 0.6086\n",
      "Recall: 0.5935\n",
      "F1: 0.6009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 42/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 42/100: 100%|██████████| 10/10 [00:01<00:00,  5.07it/s, loss=0.4259, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 181, 1: 109}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90 43]\n",
      " [91 66]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6885\n",
      "Accuracy: 0.5379\n",
      "Precision: 0.6055\n",
      "Recall: 0.4204\n",
      "F1: 0.4962\n",
      "Auc: 0.5583\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 43/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6390, acc=0.6562, lr=0.00000633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6490\n",
      "Accuracy: 0.6272\n",
      "Precision: 0.6233\n",
      "Recall: 0.5703\n",
      "F1: 0.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 43/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 43/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.2785, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 157, 1: 133}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[80 53]\n",
      " [77 80]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6942\n",
      "Accuracy: 0.5517\n",
      "Precision: 0.6015\n",
      "Recall: 0.5096\n",
      "F1: 0.5517\n",
      "Auc: 0.5551\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 44/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.5760, acc=0.7812, lr=0.00000622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6465\n",
      "Accuracy: 0.6317\n",
      "Precision: 0.6147\n",
      "Recall: 0.6327\n",
      "F1: 0.6236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 44/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 44/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4467, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 222, 1: 68}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103  30]\n",
      " [119  38]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7441\n",
      "Accuracy: 0.4862\n",
      "Precision: 0.5588\n",
      "Recall: 0.2420\n",
      "F1: 0.3378\n",
      "Auc: 0.5548\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 45/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6774, acc=0.5625, lr=0.00000611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6498\n",
      "Accuracy: 0.6176\n",
      "Precision: 0.6122\n",
      "Recall: 0.5573\n",
      "F1: 0.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 45/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 45/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5581, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 227, 1: 63}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[104  29]\n",
      " [123  34]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7525\n",
      "Accuracy: 0.4759\n",
      "Precision: 0.5397\n",
      "Recall: 0.2166\n",
      "F1: 0.3091\n",
      "Auc: 0.5518\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 46/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6639, acc=0.5625, lr=0.00000600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6481\n",
      "Accuracy: 0.6071\n",
      "Precision: 0.5876\n",
      "Recall: 0.6292\n",
      "F1: 0.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 46/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 46/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5385, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 207, 1: 83}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  37]\n",
      " [111  46]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7230\n",
      "Accuracy: 0.4897\n",
      "Precision: 0.5542\n",
      "Recall: 0.2930\n",
      "F1: 0.3833\n",
      "Auc: 0.5540\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 47/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6395, acc=0.5938, lr=0.00000589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6405\n",
      "Accuracy: 0.6354\n",
      "Precision: 0.6315\n",
      "Recall: 0.5827\n",
      "F1: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 47/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 47/100: 100%|██████████| 10/10 [00:01<00:00,  5.03it/s, loss=0.5111, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 210, 1: 80}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 97  36]\n",
      " [113  44]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7428\n",
      "Accuracy: 0.4862\n",
      "Precision: 0.5500\n",
      "Recall: 0.2803\n",
      "F1: 0.3713\n",
      "Auc: 0.5538\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 48/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6773, acc=0.4688, lr=0.00000578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6433\n",
      "Accuracy: 0.6213\n",
      "Precision: 0.6118\n",
      "Recall: 0.5901\n",
      "F1: 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 48/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 48/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.4433, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 193, 1: 97}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 90  43]\n",
      " [103  54]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7176\n",
      "Accuracy: 0.4966\n",
      "Precision: 0.5567\n",
      "Recall: 0.3439\n",
      "F1: 0.4252\n",
      "Auc: 0.5513\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 49/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6152, acc=0.6250, lr=0.00000567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6401\n",
      "Accuracy: 0.6310\n",
      "Precision: 0.6176\n",
      "Recall: 0.6157\n",
      "F1: 0.6167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 49/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 49/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4820, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 221, 1: 69}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[100  33]\n",
      " [121  36]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7585\n",
      "Accuracy: 0.4690\n",
      "Precision: 0.5217\n",
      "Recall: 0.2293\n",
      "F1: 0.3186\n",
      "Auc: 0.5485\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 50/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7632, acc=0.5625, lr=0.00000556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6448\n",
      "Accuracy: 0.6354\n",
      "Precision: 0.6234\n",
      "Recall: 0.6157\n",
      "F1: 0.6196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 50/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 50/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.6677, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 237, 1: 53}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  24]\n",
      " [128  29]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7891\n",
      "Accuracy: 0.4759\n",
      "Precision: 0.5472\n",
      "Recall: 0.1847\n",
      "F1: 0.2762\n",
      "Auc: 0.5467\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 51/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.5987, acc=0.6562, lr=0.00000544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6347\n",
      "Accuracy: 0.6376\n",
      "Precision: 0.6233\n",
      "Recall: 0.6281\n",
      "F1: 0.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 51/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 51/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.6965, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 242, 1: 48}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[111  22]\n",
      " [131  26]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8020\n",
      "Accuracy: 0.4724\n",
      "Precision: 0.5417\n",
      "Recall: 0.1656\n",
      "F1: 0.2537\n",
      "Auc: 0.5471\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 52/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.5773, acc=0.7500, lr=0.00000533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6319\n",
      "Accuracy: 0.6369\n",
      "Precision: 0.6306\n",
      "Recall: 0.6015\n",
      "F1: 0.6157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 52/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 52/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5498, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 224, 1: 66}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[102  31]\n",
      " [122  35]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7731\n",
      "Accuracy: 0.4724\n",
      "Precision: 0.5303\n",
      "Recall: 0.2229\n",
      "F1: 0.3139\n",
      "Auc: 0.5471\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 53/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.5661, acc=0.6562, lr=0.00000522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6456\n",
      "Accuracy: 0.6205\n",
      "Precision: 0.6139\n",
      "Recall: 0.5741\n",
      "F1: 0.5933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 53/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 53/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.3008, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 118, 1: 172}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64  69]\n",
      " [ 54 103]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.6938\n",
      "Accuracy: 0.5759\n",
      "Precision: 0.5988\n",
      "Recall: 0.6561\n",
      "F1: 0.6261\n",
      "Auc: 0.5457\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 54/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.6800, acc=0.6250, lr=0.00000511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6391\n",
      "Accuracy: 0.6310\n",
      "Precision: 0.6232\n",
      "Recall: 0.6022\n",
      "F1: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 54/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 54/100: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, loss=0.3203, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 137, 1: 153}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[72 61]\n",
      " [65 92]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7104\n",
      "Accuracy: 0.5655\n",
      "Precision: 0.6013\n",
      "Recall: 0.5860\n",
      "F1: 0.5935\n",
      "Auc: 0.5465\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 55/100: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s, loss=0.6287, acc=0.5938, lr=0.00000500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6372\n",
      "Accuracy: 0.6295\n",
      "Precision: 0.6244\n",
      "Recall: 0.5899\n",
      "F1: 0.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 55/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 55/100: 100%|██████████| 10/10 [00:02<00:00,  4.03it/s, loss=0.5566, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 197, 1: 93}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 92  41]\n",
      " [105  52]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7593\n",
      "Accuracy: 0.4966\n",
      "Precision: 0.5591\n",
      "Recall: 0.3312\n",
      "F1: 0.4160\n",
      "Auc: 0.5453\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 56/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5378, acc=0.7812, lr=0.00000489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6413\n",
      "Accuracy: 0.6190\n",
      "Precision: 0.5969\n",
      "Recall: 0.6502\n",
      "F1: 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 56/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 56/100: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s, loss=0.5832, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 181, 1: 109}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91 42]\n",
      " [90 67]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7405\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6147\n",
      "Recall: 0.4268\n",
      "F1: 0.5038\n",
      "Auc: 0.5446\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 57/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6229, acc=0.6562, lr=0.00000478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6292\n",
      "Accuracy: 0.6406\n",
      "Precision: 0.6440\n",
      "Recall: 0.5694\n",
      "F1: 0.6044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 57/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 57/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.4342, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 169, 1: 121}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[84 49]\n",
      " [85 72]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7569\n",
      "Accuracy: 0.5379\n",
      "Precision: 0.5950\n",
      "Recall: 0.4586\n",
      "F1: 0.5180\n",
      "Auc: 0.5437\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 58/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.7336, acc=0.5938, lr=0.00000467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6378\n",
      "Accuracy: 0.6466\n",
      "Precision: 0.6357\n",
      "Recall: 0.6308\n",
      "F1: 0.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 58/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 58/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.4517, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 160, 1: 130}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[81 52]\n",
      " [79 78]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7372\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.6000\n",
      "Recall: 0.4968\n",
      "F1: 0.5436\n",
      "Auc: 0.5400\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 59/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5878, acc=0.5625, lr=0.00000456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6290\n",
      "Accuracy: 0.6562\n",
      "Precision: 0.6528\n",
      "Recall: 0.6084\n",
      "F1: 0.6298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 59/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 59/100: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s, loss=0.4686, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 162, 1: 128}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[82 51]\n",
      " [80 77]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7380\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.6016\n",
      "Recall: 0.4904\n",
      "F1: 0.5404\n",
      "Auc: 0.5414\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 60/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5582, acc=0.7812, lr=0.00000444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6346\n",
      "Accuracy: 0.6391\n",
      "Precision: 0.6279\n",
      "Recall: 0.6231\n",
      "F1: 0.6255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 60/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 60/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.5386, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 196, 1: 94}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 92  41]\n",
      " [104  53]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7475\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.5638\n",
      "Recall: 0.3376\n",
      "F1: 0.4223\n",
      "Auc: 0.5370\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 61/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6174, acc=0.6562, lr=0.00000433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6312\n",
      "Accuracy: 0.6421\n",
      "Precision: 0.6334\n",
      "Recall: 0.6090\n",
      "F1: 0.6210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 61/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 61/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.4943, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 195, 1: 95}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 92  41]\n",
      " [103  54]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7538\n",
      "Accuracy: 0.5034\n",
      "Precision: 0.5684\n",
      "Recall: 0.3439\n",
      "F1: 0.4286\n",
      "Auc: 0.5363\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 62/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6332, acc=0.5938, lr=0.00000422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6320\n",
      "Accuracy: 0.6287\n",
      "Precision: 0.6165\n",
      "Recall: 0.6117\n",
      "F1: 0.6141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 62/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 62/100: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s, loss=0.6916, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 222, 1: 68}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[102  31]\n",
      " [120  37]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7838\n",
      "Accuracy: 0.4793\n",
      "Precision: 0.5441\n",
      "Recall: 0.2357\n",
      "F1: 0.3289\n",
      "Auc: 0.5331\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 63/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5327, acc=0.7812, lr=0.00000411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6230\n",
      "Accuracy: 0.6615\n",
      "Precision: 0.6509\n",
      "Recall: 0.6399\n",
      "F1: 0.6454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 63/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 63/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.3965, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 153, 1: 137}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[75 58]\n",
      " [78 79]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7582\n",
      "Accuracy: 0.5310\n",
      "Precision: 0.5766\n",
      "Recall: 0.5032\n",
      "F1: 0.5374\n",
      "Auc: 0.5392\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 64/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5922, acc=0.5938, lr=0.00000400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6234\n",
      "Accuracy: 0.6473\n",
      "Precision: 0.6290\n",
      "Recall: 0.6465\n",
      "F1: 0.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 64/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 64/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.6821, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 227, 1: 63}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[106  27]\n",
      " [121  36]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8336\n",
      "Accuracy: 0.4897\n",
      "Precision: 0.5714\n",
      "Recall: 0.2293\n",
      "F1: 0.3273\n",
      "Auc: 0.5333\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 65/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.7096, acc=0.5625, lr=0.00000389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6280\n",
      "Accuracy: 0.6473\n",
      "Precision: 0.6436\n",
      "Recall: 0.6019\n",
      "F1: 0.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 65/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 65/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.6374, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 221, 1: 69}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[101  32]\n",
      " [120  37]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8118\n",
      "Accuracy: 0.4759\n",
      "Precision: 0.5362\n",
      "Recall: 0.2357\n",
      "F1: 0.3274\n",
      "Auc: 0.5305\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 66/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.7391, acc=0.5625, lr=0.00000378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6172\n",
      "Accuracy: 0.6473\n",
      "Precision: 0.6422\n",
      "Recall: 0.6065\n",
      "F1: 0.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 66/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 66/100: 100%|██████████| 10/10 [00:02<00:00,  4.06it/s, loss=0.4341, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 150, 1: 140}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[76 57]\n",
      " [74 83]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7422\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.5929\n",
      "Recall: 0.5287\n",
      "F1: 0.5589\n",
      "Auc: 0.5371\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 67/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6663, acc=0.5938, lr=0.00000367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6284\n",
      "Accuracy: 0.6369\n",
      "Precision: 0.6317\n",
      "Recall: 0.5867\n",
      "F1: 0.6083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 67/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 67/100: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s, loss=0.7735, acc=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 234, 1: 56}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[107  26]\n",
      " [127  30]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8137\n",
      "Accuracy: 0.4724\n",
      "Precision: 0.5357\n",
      "Recall: 0.1911\n",
      "F1: 0.2817\n",
      "Auc: 0.5308\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 68/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5762, acc=0.6562, lr=0.00000356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6111\n",
      "Accuracy: 0.6592\n",
      "Precision: 0.6484\n",
      "Recall: 0.6404\n",
      "F1: 0.6444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 68/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 68/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.7704, acc=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 233, 1: 57}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[107  26]\n",
      " [126  31]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8445\n",
      "Accuracy: 0.4759\n",
      "Precision: 0.5439\n",
      "Recall: 0.1975\n",
      "F1: 0.2897\n",
      "Auc: 0.5329\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 69/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5650, acc=0.7188, lr=0.00000344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6234\n",
      "Accuracy: 0.6577\n",
      "Precision: 0.6604\n",
      "Recall: 0.5951\n",
      "F1: 0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 69/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 69/100: 100%|██████████| 10/10 [00:02<00:00,  4.06it/s, loss=0.3669, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 147, 1: 143}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[73 60]\n",
      " [74 83]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7401\n",
      "Accuracy: 0.5379\n",
      "Precision: 0.5804\n",
      "Recall: 0.5287\n",
      "F1: 0.5533\n",
      "Auc: 0.5347\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 70/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6268, acc=0.6250, lr=0.00000333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6161\n",
      "Accuracy: 0.6518\n",
      "Precision: 0.6468\n",
      "Recall: 0.6169\n",
      "F1: 0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 70/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 70/100: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s, loss=0.5792, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 205, 1: 85}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  37]\n",
      " [109  48]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7964\n",
      "Accuracy: 0.4966\n",
      "Precision: 0.5647\n",
      "Recall: 0.3057\n",
      "F1: 0.3967\n",
      "Auc: 0.5323\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 71/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5773, acc=0.7500, lr=0.00000322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6187\n",
      "Accuracy: 0.6369\n",
      "Precision: 0.6272\n",
      "Recall: 0.6117\n",
      "F1: 0.6193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 71/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 71/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.7236, acc=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 222, 1: 68}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103  30]\n",
      " [119  38]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7924\n",
      "Accuracy: 0.4862\n",
      "Precision: 0.5588\n",
      "Recall: 0.2420\n",
      "F1: 0.3378\n",
      "Auc: 0.5294\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 72/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 72/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6222, acc=0.6562, lr=0.00000311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6206\n",
      "Accuracy: 0.6540\n",
      "Precision: 0.6459\n",
      "Recall: 0.6250\n",
      "F1: 0.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 72/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 72/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.6831, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 227, 1: 63}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105  28]\n",
      " [122  35]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8266\n",
      "Accuracy: 0.4828\n",
      "Precision: 0.5556\n",
      "Recall: 0.2229\n",
      "F1: 0.3182\n",
      "Auc: 0.5297\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 73/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6731, acc=0.5312, lr=0.00000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6194\n",
      "Accuracy: 0.6481\n",
      "Precision: 0.6511\n",
      "Recall: 0.5818\n",
      "F1: 0.6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 73/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 73/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.3450, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 144, 1: 146}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[72 61]\n",
      " [72 85]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7450\n",
      "Accuracy: 0.5414\n",
      "Precision: 0.5822\n",
      "Recall: 0.5414\n",
      "F1: 0.5611\n",
      "Auc: 0.5335\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 74/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5823, acc=0.6875, lr=0.00000289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6161\n",
      "Accuracy: 0.6644\n",
      "Precision: 0.6443\n",
      "Recall: 0.6713\n",
      "F1: 0.6576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 74/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 74/100: 100%|██████████| 10/10 [00:02<00:00,  4.06it/s, loss=0.5215, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 192, 1: 98}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[93 40]\n",
      " [99 58]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7804\n",
      "Accuracy: 0.5207\n",
      "Precision: 0.5918\n",
      "Recall: 0.3694\n",
      "F1: 0.4549\n",
      "Auc: 0.5316\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 75/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6632, acc=0.6875, lr=0.00000278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6065\n",
      "Accuracy: 0.6689\n",
      "Precision: 0.6575\n",
      "Recall: 0.6585\n",
      "F1: 0.6580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 75/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 75/100: 100%|██████████| 10/10 [00:02<00:00,  4.06it/s, loss=0.5115, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 181, 1: 109}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90 43]\n",
      " [91 66]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7795\n",
      "Accuracy: 0.5379\n",
      "Precision: 0.6055\n",
      "Recall: 0.4204\n",
      "F1: 0.4962\n",
      "Auc: 0.5341\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 76/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6281, acc=0.6250, lr=0.00000267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6073\n",
      "Accuracy: 0.6927\n",
      "Precision: 0.6941\n",
      "Recall: 0.6502\n",
      "F1: 0.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 76/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 76/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.4829, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 158, 1: 132}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[80 53]\n",
      " [78 79]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7899\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.5985\n",
      "Recall: 0.5032\n",
      "F1: 0.5467\n",
      "Auc: 0.5349\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 77/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 77/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.6379, acc=0.6875, lr=0.00000256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6089\n",
      "Accuracy: 0.6689\n",
      "Precision: 0.6563\n",
      "Recall: 0.6553\n",
      "F1: 0.6558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 77/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 77/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.4964, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 166, 1: 124}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83 50]\n",
      " [83 74]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7796\n",
      "Accuracy: 0.5414\n",
      "Precision: 0.5968\n",
      "Recall: 0.4713\n",
      "F1: 0.5267\n",
      "Auc: 0.5318\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 78/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5523, acc=0.6875, lr=0.00000244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6153\n",
      "Accuracy: 0.6741\n",
      "Precision: 0.6705\n",
      "Recall: 0.6331\n",
      "F1: 0.6513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 78/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 78/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.5560, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 185, 1: 105}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91 42]\n",
      " [94 63]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7914\n",
      "Accuracy: 0.5310\n",
      "Precision: 0.6000\n",
      "Recall: 0.4013\n",
      "F1: 0.4809\n",
      "Auc: 0.5280\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 79/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 79/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5474, acc=0.6250, lr=0.00000233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6131\n",
      "Accuracy: 0.6607\n",
      "Precision: 0.6419\n",
      "Recall: 0.6677\n",
      "F1: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 79/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 79/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.4235, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 153, 1: 137}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[76 57]\n",
      " [77 80]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7628\n",
      "Accuracy: 0.5379\n",
      "Precision: 0.5839\n",
      "Recall: 0.5096\n",
      "F1: 0.5442\n",
      "Auc: 0.5293\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 80/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 80/100: 100%|██████████| 42/42 [00:25<00:00,  1.67it/s, loss=0.5093, acc=0.7812, lr=0.00000222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6099\n",
      "Accuracy: 0.6652\n",
      "Precision: 0.6602\n",
      "Recall: 0.6296\n",
      "F1: 0.6445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 80/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 80/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.6134, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 176, 1: 114}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90 43]\n",
      " [86 71]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7970\n",
      "Accuracy: 0.5552\n",
      "Precision: 0.6228\n",
      "Recall: 0.4522\n",
      "F1: 0.5240\n",
      "Auc: 0.5312\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 81/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 81/100: 100%|██████████| 42/42 [00:21<00:00,  1.93it/s, loss=0.6647, acc=0.6250, lr=0.00000211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6111\n",
      "Accuracy: 0.6615\n",
      "Precision: 0.6488\n",
      "Recall: 0.6518\n",
      "F1: 0.6503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 81/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 81/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.4365, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 151, 1: 139}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[76 57]\n",
      " [75 82]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7747\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.5899\n",
      "Recall: 0.5223\n",
      "F1: 0.5541\n",
      "Auc: 0.5316\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 82/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 82/100: 100%|██████████| 42/42 [00:24<00:00,  1.72it/s, loss=0.5025, acc=0.7188, lr=0.00000200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6054\n",
      "Accuracy: 0.6726\n",
      "Precision: 0.6683\n",
      "Recall: 0.6331\n",
      "F1: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 82/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 82/100: 100%|██████████| 10/10 [00:02<00:00,  4.03it/s, loss=0.4984, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 159, 1: 131}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[80 53]\n",
      " [79 78]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7764\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.5954\n",
      "Recall: 0.4968\n",
      "F1: 0.5417\n",
      "Auc: 0.5330\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 83/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 83/100: 100%|██████████| 42/42 [00:23<00:00,  1.75it/s, loss=0.6434, acc=0.7188, lr=0.00000189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6053\n",
      "Accuracy: 0.6667\n",
      "Precision: 0.6544\n",
      "Recall: 0.6564\n",
      "F1: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 83/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 83/100: 100%|██████████| 10/10 [00:02<00:00,  4.04it/s, loss=0.4357, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 154, 1: 136}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[78 55]\n",
      " [76 81]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7989\n",
      "Accuracy: 0.5483\n",
      "Precision: 0.5956\n",
      "Recall: 0.5159\n",
      "F1: 0.5529\n",
      "Auc: 0.5333\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 84/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 84/100: 100%|██████████| 42/42 [00:24<00:00,  1.68it/s, loss=0.5242, acc=0.7188, lr=0.00000178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6004\n",
      "Accuracy: 0.6734\n",
      "Precision: 0.6651\n",
      "Recall: 0.6518\n",
      "F1: 0.6584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 84/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 84/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.7405, acc=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 208, 1: 82}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 98  35]\n",
      " [110  47]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8379\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.5732\n",
      "Recall: 0.2994\n",
      "F1: 0.3933\n",
      "Auc: 0.5289\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 85/100: 100%|██████████| 42/42 [00:24<00:00,  1.68it/s, loss=0.4883, acc=0.6875, lr=0.00000167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6122\n",
      "Accuracy: 0.6548\n",
      "Precision: 0.6479\n",
      "Recall: 0.6219\n",
      "F1: 0.6346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 85/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 85/100: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.5581, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 167, 1: 123}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[84 49]\n",
      " [83 74]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7865\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6016\n",
      "Recall: 0.4713\n",
      "F1: 0.5286\n",
      "Auc: 0.5310\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 86/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 86/100: 100%|██████████| 42/42 [00:24<00:00,  1.71it/s, loss=0.6173, acc=0.6562, lr=0.00000156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6055\n",
      "Accuracy: 0.6629\n",
      "Precision: 0.6590\n",
      "Recall: 0.6192\n",
      "F1: 0.6385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 86/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 86/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5723, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 173, 1: 117}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[88 45]\n",
      " [85 72]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8048\n",
      "Accuracy: 0.5517\n",
      "Precision: 0.6154\n",
      "Recall: 0.4586\n",
      "F1: 0.5255\n",
      "Auc: 0.5305\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 87/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 87/100: 100%|██████████| 42/42 [00:24<00:00,  1.69it/s, loss=0.5597, acc=0.7188, lr=0.00000144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6041\n",
      "Accuracy: 0.6741\n",
      "Precision: 0.6672\n",
      "Recall: 0.6466\n",
      "F1: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 87/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 87/100: 100%|██████████| 10/10 [00:02<00:00,  4.06it/s, loss=0.5141, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 156, 1: 134}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[77 56]\n",
      " [79 78]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7841\n",
      "Accuracy: 0.5345\n",
      "Precision: 0.5821\n",
      "Recall: 0.4968\n",
      "F1: 0.5361\n",
      "Auc: 0.5313\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 88/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 88/100: 100%|██████████| 42/42 [00:24<00:00,  1.68it/s, loss=0.6817, acc=0.6875, lr=0.00000133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6049\n",
      "Accuracy: 0.6696\n",
      "Precision: 0.6614\n",
      "Recall: 0.6451\n",
      "F1: 0.6531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 88/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 88/100: 100%|██████████| 10/10 [00:02<00:00,  4.15it/s, loss=0.5891, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 167, 1: 123}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83 50]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7943\n",
      "Accuracy: 0.5379\n",
      "Precision: 0.5935\n",
      "Recall: 0.4650\n",
      "F1: 0.5214\n",
      "Auc: 0.5296\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 89/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 89/100: 100%|██████████| 42/42 [00:20<00:00,  2.03it/s, loss=0.6282, acc=0.6875, lr=0.00000122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6086\n",
      "Accuracy: 0.6577\n",
      "Precision: 0.6540\n",
      "Recall: 0.6136\n",
      "F1: 0.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 89/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 89/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.5723, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 169, 1: 121}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85 48]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7972\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6033\n",
      "Recall: 0.4650\n",
      "F1: 0.5252\n",
      "Auc: 0.5287\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 90/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 90/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6278, acc=0.6562, lr=0.00000111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6099\n",
      "Accuracy: 0.6600\n",
      "Precision: 0.6537\n",
      "Recall: 0.6223\n",
      "F1: 0.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 90/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 90/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.6921, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 198, 1: 92}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  37]\n",
      " [102  55]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8167\n",
      "Accuracy: 0.5207\n",
      "Precision: 0.5978\n",
      "Recall: 0.3503\n",
      "F1: 0.4418\n",
      "Auc: 0.5275\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 91/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 91/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.5651, acc=0.7188, lr=0.00000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6015\n",
      "Accuracy: 0.6756\n",
      "Precision: 0.6828\n",
      "Recall: 0.6090\n",
      "F1: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 91/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 91/100: 100%|██████████| 10/10 [00:01<00:00,  5.07it/s, loss=0.5850, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 177, 1: 113}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89 44]\n",
      " [88 69]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8024\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6106\n",
      "Recall: 0.4395\n",
      "F1: 0.5111\n",
      "Auc: 0.5306\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 92/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 92/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.5963, acc=0.7188, lr=0.00000089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6051\n",
      "Accuracy: 0.6786\n",
      "Precision: 0.6622\n",
      "Recall: 0.6846\n",
      "F1: 0.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 92/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 92/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5183, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 166, 1: 124}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[82 51]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7863\n",
      "Accuracy: 0.5345\n",
      "Precision: 0.5887\n",
      "Recall: 0.4650\n",
      "F1: 0.5196\n",
      "Auc: 0.5285\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 93/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 93/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.5723, acc=0.7500, lr=0.00000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6106\n",
      "Accuracy: 0.6652\n",
      "Precision: 0.6656\n",
      "Recall: 0.6142\n",
      "F1: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 93/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 93/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.4797, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 162, 1: 128}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[79 54]\n",
      " [83 74]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7832\n",
      "Accuracy: 0.5276\n",
      "Precision: 0.5781\n",
      "Recall: 0.4713\n",
      "F1: 0.5193\n",
      "Auc: 0.5264\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 94/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 94/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7095, acc=0.5312, lr=0.00000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6071\n",
      "Accuracy: 0.6570\n",
      "Precision: 0.6517\n",
      "Recall: 0.6246\n",
      "F1: 0.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 94/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 94/100: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, loss=0.5390, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 171, 1: 119}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[86 47]\n",
      " [85 72]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7958\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6050\n",
      "Recall: 0.4586\n",
      "F1: 0.5217\n",
      "Auc: 0.5271\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 95/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 95/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.6894, acc=0.6250, lr=0.00000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6008\n",
      "Accuracy: 0.6860\n",
      "Precision: 0.6789\n",
      "Recall: 0.6600\n",
      "F1: 0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 95/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 95/100: 100%|██████████| 10/10 [00:01<00:00,  5.03it/s, loss=0.5263, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 169, 1: 121}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85 48]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7959\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6033\n",
      "Recall: 0.4650\n",
      "F1: 0.5252\n",
      "Auc: 0.5272\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 96/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 96/100: 100%|██████████| 42/42 [00:20<00:00,  2.09it/s, loss=0.7268, acc=0.4688, lr=0.00000044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6012\n",
      "Accuracy: 0.6667\n",
      "Precision: 0.6588\n",
      "Recall: 0.6425\n",
      "F1: 0.6505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 96/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 96/100: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, loss=0.5412, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 169, 1: 121}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85 48]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8030\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6033\n",
      "Recall: 0.4650\n",
      "F1: 0.5252\n",
      "Auc: 0.5278\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 97/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 97/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.4929, acc=0.7500, lr=0.00000033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.5954\n",
      "Accuracy: 0.6771\n",
      "Precision: 0.6682\n",
      "Recall: 0.6538\n",
      "F1: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 97/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 97/100: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, loss=0.5353, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 169, 1: 121}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85 48]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8070\n",
      "Accuracy: 0.5448\n",
      "Precision: 0.6033\n",
      "Recall: 0.4650\n",
      "F1: 0.5252\n",
      "Auc: 0.5275\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 98/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 98/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.5974, acc=0.6562, lr=0.00000022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.5966\n",
      "Accuracy: 0.6704\n",
      "Precision: 0.6688\n",
      "Recall: 0.6308\n",
      "F1: 0.6492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 98/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 98/100: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s, loss=0.5525, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 174, 1: 116}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[87 46]\n",
      " [87 70]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8124\n",
      "Accuracy: 0.5414\n",
      "Precision: 0.6034\n",
      "Recall: 0.4459\n",
      "F1: 0.5128\n",
      "Auc: 0.5268\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 99/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 99/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.5667, acc=0.6875, lr=0.00000011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.6046\n",
      "Accuracy: 0.6615\n",
      "Precision: 0.6565\n",
      "Recall: 0.6271\n",
      "F1: 0.6414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 99/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 99/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.5040, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 166, 1: 124}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[82 51]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.7968\n",
      "Accuracy: 0.5345\n",
      "Precision: 0.5887\n",
      "Recall: 0.4650\n",
      "F1: 0.5196\n",
      "Auc: 0.5266\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 100/100:   0%|          | 0/42 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training Epoch 100/100: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s, loss=0.7359, acc=0.5938, lr=0.00000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "Loss: 0.5932\n",
      "Accuracy: 0.6793\n",
      "Precision: 0.6682\n",
      "Recall: 0.6610\n",
      "F1: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 100/100:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation Epoch 100/100: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s, loss=0.5125, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Distribution: {0: 168, 1: 122}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[84 49]\n",
      " [84 73]]\n",
      "\n",
      "Validation Metrics:\n",
      "Loss: 0.8009\n",
      "Accuracy: 0.5414\n",
      "Precision: 0.5984\n",
      "Recall: 0.4650\n",
      "F1: 0.5233\n",
      "Auc: 0.5272\n",
      "\n",
      "Loaded best model from epoch 18\n",
      "\n",
      "Training completed!\n",
      "Best validation F1 score: 0.6975\n",
      "Could not plot training history: 'train_acc'\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Test Evaluation: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s]\n",
      "/tmp/ipykernel_3660271/914250593.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified['confidence'] = misclassified.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Confusion Matrix:\n",
      "[[81 52]\n",
      " [72 86]]\n",
      "\n",
      "Test Set Metrics:\n",
      "Loss: 0.7387\n",
      "Accuracy: 0.5739\n",
      "Precision: 0.6232\n",
      "Recall: 0.5443\n",
      "F1: 0.5811\n",
      "Auc: 0.5997\n",
      "Saved detailed test predictions to 'test_predictions.csv'\n",
      "\n",
      "Analyzing results...\n",
      "Number of misclassified examples: 124\n",
      "\n",
      "Most confident errors:\n",
      "     drug_id pdb_id  true_label  predicted  confidence\n",
      "163  DB00398   2LCM           0          1    0.942866\n",
      "14   DB01028   4COF           1          0    0.921042\n",
      "108  DB00799   4JQI           0          1    0.916635\n",
      "56   DB13269   2KAV           1          0    0.906380\n",
      "36   DB09088   2KAV           1          0    0.904911\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_complete_training():\n",
    "    \"\"\"Complete pipeline for training and evaluating the DTI model\"\"\"\n",
    "    # Initialize components\n",
    "    model, trainer, test_loader, test_dataset, tokenizer, device = initialize_training()\n",
    "    \n",
    "    # Train model\n",
    "    best_f1 = trainer.train()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_metrics, test_results = trainer.evaluate_test_set(test_loader)\n",
    "    \n",
    "    # Analysis of results\n",
    "    print(\"\\nAnalyzing results...\")\n",
    "    \n",
    "    # Find misclassified examples\n",
    "    misclassified = test_results[test_results['true_label'] != test_results['predicted']]\n",
    "    print(f\"Number of misclassified examples: {len(misclassified)}\")\n",
    "    \n",
    "    # Find examples where model is most confident but wrong\n",
    "    if len(misclassified) > 0:\n",
    "        misclassified['confidence'] = misclassified.apply(\n",
    "            lambda row: row['probability'] if row['predicted'] == 1 else 1 - row['probability'], \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        most_confident_errors = misclassified.sort_values('confidence', ascending=False).head(5)\n",
    "        print(\"\\nMost confident errors:\")\n",
    "        print(most_confident_errors[['drug_id', 'pdb_id', 'true_label', 'predicted', 'confidence']])\n",
    "    \n",
    "    return model, test_metrics, test_results, test_dataset, tokenizer, device\n",
    "\n",
    "# Call the function to start training\n",
    "if __name__ == \"__main__\":\n",
    "    model, test_metrics, test_results, test_dataset, tokenizer, device = run_complete_training()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7000098,
     "sourceId": 11210448,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
